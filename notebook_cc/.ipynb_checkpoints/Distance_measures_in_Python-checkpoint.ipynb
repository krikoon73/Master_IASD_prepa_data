{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance measures in Python using the NLTK package\n",
    "There are a number of distance measures that are readily available using the NLTK package pf Python. The objective of this tutorial is to introduce you to the utilisation of some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String-Based Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Distance\n",
    "Edit Distance (a.k.a. Levenshtein Distance) is a measure of similarity between two strings referred to as the source string and the target string. \n",
    "\n",
    "The distance between the source string and the target string is the minimum number of edit operations (deletions, insertions, or substitutions) required to transform the source into the target. The lower the distance, the more similar the two strings. \n",
    "\n",
    "Among the common applications of the Edit Distance algorithm are: spell checking, plagiarism detection, and duplicate detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    " \n",
    "w1 = 'mapping'\n",
    "w2 = 'mappings'\n",
    "\n",
    " \n",
    "nltk.edit_distance(w1, w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is 1 because the difference between “mapping” and “mappings” is only one character, “s”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2\n",
    "Basic Spelling Checker: Let’s assume you have a mistaken word and a list of possible words and you want to know the nearest suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 7\n",
      "bag 6\n",
      "drawing 4\n",
      "listing 1\n",
      "linking 2\n",
      "living 2\n",
      "lighting 1\n",
      "orange 6\n",
      "walking 4\n",
      "zoo 7\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "mistake = \"ligting\"\n",
    " \n",
    "words = ['apple', 'bag', 'drawing', 'listing', 'linking', 'living', 'lighting', 'orange', 'walking', 'zoo']\n",
    " \n",
    "for word in words:\n",
    "    ed = nltk.edit_distance(mistake, word)\n",
    "    print(word, ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Can you explain the above results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, comparing the mistaken word “ligting” to each word in our list,  the least Edit Distance is 1 for words: “listing” and “lighting” which means they are the best spelling suggestions for “ligting”. Yes, a smaller Edit Distance between two strings means they are more similar than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "You may also want to compare entire sentences or paragraphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Edit Distance between sent1 and sent2\n",
      "19 Edit Distance between sent1 and sent3\n",
      "32 Edit Distance between sent1 and sent4\n",
      "33 Edit Distance between sent1 and sent5\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "sentence1 = \"It might help to re-install Python if possible.\"\n",
    "sentence2 = \"It can help to install Python again if possible.\"\n",
    "sentence3 = \"It can be so helpful to reinstall C++ if possible.\"\n",
    "sentence4 = \"help It possible Python to re-install if might.\" # This has the same words as sent1 with a different order.\n",
    "sentence5 = \"I love Python programming.\"\n",
    " \n",
    "ed_sentence_1_2 = nltk.edit_distance(sentence1, sentence2)\n",
    "ed_sentence_1_3 = nltk.edit_distance(sentence1, sentence3)\n",
    "ed_sentence_1_4 = nltk.edit_distance(sentence1, sentence4)\n",
    "ed_sentence_1_5 = nltk.edit_distance(sentence1, sentence5)\n",
    " \n",
    " \n",
    "print(ed_sentence_1_2, 'Edit Distance between sent1 and sent2')\n",
    "print(ed_sentence_1_3, 'Edit Distance between sent1 and sent3')\n",
    "print(ed_sentence_1_4, 'Edit Distance between sent1 and sent4')\n",
    "print(ed_sentence_1_5, 'Edit Distance between sent1 and sent5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Distance\n",
    "Jaccard Distance is a measure of how dissimilar two sets are.  The lower the distance, the more similar the two strings. \n",
    "\n",
    "J(X,Y) = |X∩Y| / |X∪Y|\n",
    "\n",
    "D(X,Y) = 1 – J(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we have two strings: “mapping” and “mappings”, the intersection of the two sets is 6 because there are 7 similar characters, but the “p” is repeated while we need a set, i.e. unique characters, and the union of the two sets is 7, so the Jaccard Similarity Index is 6/7 = 0.857 and the Jaccard Distance is 1 – 0.857 = 0.142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "w1 = set('mapping')\n",
    "w2 = set('mappings')\n",
    " \n",
    "nltk.jaccard_distance(w1, w2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that unlike Edit Distance, you cannot just run Jaccard Distance on the strings directly; you must first convert them to the set type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2\n",
    "Basic Spelling Checker: It is the same example we had with the Edit Distance algorithm; now we are testing it with the Jaccard Distance algorithm. Let’s assume you have a mistaken word and a list of possible words and you want to know the nearest suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 0.875\n",
      "bag 0.8571428571428571\n",
      "drawing 0.6666666666666666\n",
      "listing 0.16666666666666666\n",
      "linking 0.3333333333333333\n",
      "living 0.3333333333333333\n",
      "lighting 0.16666666666666666\n",
      "orange 0.7777777777777778\n",
      "walking 0.5\n",
      "zoo 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "mistake = \"ligting\"\n",
    " \n",
    "words = ['apple', 'bag', 'drawing', 'listing', 'linking', 'living', 'lighting', 'orange', 'walking', 'zoo']\n",
    " \n",
    "for word in words:\n",
    "    jd = nltk.jaccard_distance(set(mistake), set(word))\n",
    "    print(word, jd)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, comparing the mistaken word “ligting” to each word in our list,  the least Jaccard Distance is 0.166 for words: “listing” and “lighting” which means they are the best spelling suggestions for “ligting” because they have the lowest distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3\n",
    "If you are wondering if there is a difference between the output of Edit Distance and Jaccard Distance, see this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18181818181818182 Jaccard Distance between sent1 and sent2\n",
      "0.36 Jaccard Distance between sent1 and sent3\n",
      "0.0 Jaccard Distance between sent1 and sent4\n",
      "0.22727272727272727 Jaccard Distance between sent1 and sent5\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "sentence1 = set(\"It might help to re-install Python if possible.\")\n",
    "sentence2 = set(\"It can help to install Python again if possible.\")\n",
    "sentence3 = set(\"It can be so helpful to reinstall C++ if possible.\")\n",
    "sentence4 = set(\"help It possible Python to re-install if might.\") # This has the same words as sent1 with a different order.\n",
    "sentence5 = set(\"I love Python programming.\")\n",
    " \n",
    "jd_sentence_1_2 = nltk.jaccard_distance(sentence1, sentence2)\n",
    "jd_sentence_1_3 = nltk.jaccard_distance(sentence1, sentence3)\n",
    "jd_sentence_1_4 = nltk.jaccard_distance(sentence1, sentence4)\n",
    "jd_sentence_1_5 = nltk.jaccard_distance(sentence1, sentence5)\n",
    " \n",
    " \n",
    "print(jd_sentence_1_2, 'Jaccard Distance between sent1 and sent2')\n",
    "print(jd_sentence_1_3, 'Jaccard Distance between sent1 and sent3')\n",
    "print(jd_sentence_1_4, 'Jaccard Distance between sent1 and sent4')\n",
    "print(jd_sentence_1_5, 'Jaccard Distance between sent1 and sent5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like when we applied Edit Distance, sent1 and sent2 are the most similar sentences. \n",
    "\n",
    "However, look to the other results; they are completely different. The most obvious difference is that the Edit Distance between sent1 and sent4 is 32 and the Jaccard Distance is zero, which means the Jaccard Distance algorithms sees them as identical sentence because Edit Distance depends on counting edit operations from the start to end of the string while Jaccard Distance just counts the number characters and then apply some calculations on this number as mentioned above. \n",
    "\n",
    "Actually, there is no “right” or “wrong” answer; it all depends on what you really need to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams\n",
    "In general, n-gram means splitting a string in sequences with the length n. So if we have this string “abcde”, then bigrams are: ab, bc, cd, and de while trigrams will be: abc, bcd, and cde while 4-grams will be abcd, and bcde.\n",
    "\n",
    "Back to Jaccard Distance, let’s see how to use n-grams on the string directly, i.e. on the character level, or after tokenization, i.e. on the token level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43103448275862066 Jaccard Distance between sentence1 and sentence2 with ngram 3\n",
      "0.6323529411764706 Jaccard Distance between sentence1 and sentence3 with ngram 3\n",
      "0.3333333333333333 Jaccard Distance between sentence1 and sentence4 with ngram 3\n",
      "0.9047619047619048 Jaccard Distance between sentence1 and sentence5 with ngram 3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "sentence1 = \"It might help to re-install Python if possible.\"\n",
    "sentence2 = \"It can help to install Python again if possible.\"\n",
    "sentence3 = \"It can be so helpful to reinstall C++ if possible.\"\n",
    "sentence4 = \"help It possible Python to re-install if might.\" # This has the same words as sent1 with a different order.\n",
    "sentence5 = \"I love Python programming.\"\n",
    "\n",
    "ng1_chars = set(nltk.ngrams(sentence1, n=3))\n",
    "ng2_chars = set(nltk.ngrams(sentence2, n=3))\n",
    "ng3_chars = set(nltk.ngrams(sentence3, n=3))\n",
    "ng4_chars = set(nltk.ngrams(sentence4, n=3))\n",
    "ng5_chars = set(nltk.ngrams(sentence5, n=3))\n",
    " \n",
    "jd_sentence_1_2 = nltk.jaccard_distance(ng1_chars, ng2_chars)\n",
    "jd_sentence_1_3 = nltk.jaccard_distance(ng1_chars, ng3_chars)\n",
    "jd_sentence_1_4 = nltk.jaccard_distance(ng1_chars, ng4_chars)\n",
    "jd_sentence_1_5 = nltk.jaccard_distance(ng1_chars, ng5_chars)\n",
    " \n",
    "print(jd_sentence_1_2, \"Jaccard Distance between sentence1 and sentence2 with ngram 3\")\n",
    "print(jd_sentence_1_3, \"Jaccard Distance between sentence1 and sentence3 with ngram 3\")\n",
    "print(jd_sentence_1_4, \"Jaccard Distance between sentence1 and sentence4 with ngram 3\")\n",
    "print(jd_sentence_1_5, \"Jaccard Distance between sentence1 and sentence5 with ngram 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "If you want to work on word level instead of character level, you might want to apply tokenization first before calculating Edit Distance and Jaccard Distance. This can be useful if you want to exclude specific sort of tokens or if you want to run some pre-operations like  stemming (i.e., inflection in words to their root forms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we will use the previous example using n-grams and apply the jackard between n-grams of words as opposed to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286 Jaccard Distance between tokens1 and tokens2 with ngram 3\n",
      "0.9333333333333333 Jaccard Distance between tokens1 and tokens3 with ngram 3\n",
      "1.0 Jaccard Distance between tokens1 and tokens4 with ngram 3\n",
      "1.0 Jaccard Distance between tokens1 and tokens5 with ngram 3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "sent1 = \"It might help to re-install Python if possible.\"\n",
    "sent2 = \"It can help to install Python again if possible.\"\n",
    "sent3 = \"It can be so helpful to reinstall C++ if possible.\"\n",
    "sent4 = \"help It possible Python to re-install if might.\" # This has the same words as sent1 with a different order.\n",
    "sent5 = \"I love Python programming.\"\n",
    " \n",
    "tokens1 = nltk.word_tokenize(sent1) \n",
    "tokens2 = nltk.word_tokenize(sent2)\n",
    "tokens3 = nltk.word_tokenize(sent3)\n",
    "tokens4 = nltk.word_tokenize(sent4)\n",
    "tokens5 = nltk.word_tokenize(sent5)\n",
    "\n",
    "ng1_tokens = set(nltk.ngrams(tokens1, n=3))\n",
    "ng2_tokens = set(nltk.ngrams(tokens2, n=3))\n",
    "ng3_tokens = set(nltk.ngrams(tokens3, n=3))\n",
    "ng4_tokens = set(nltk.ngrams(tokens4, n=3))\n",
    "ng5_tokens = set(nltk.ngrams(tokens5, n=3))\n",
    "    \n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_tokens, ng2_tokens)\n",
    "jd_sent_1_3 = nltk.jaccard_distance(ng1_tokens, ng3_tokens)\n",
    "jd_sent_1_4 = nltk.jaccard_distance(ng1_tokens, ng4_tokens)\n",
    "jd_sent_1_5 = nltk.jaccard_distance(ng1_tokens, ng5_tokens)\n",
    "\n",
    "#jd_sent_1_2 = nltk.jaccard_distance(set(tokens1), set(tokens2))\n",
    "#jd_sent_1_3 = nltk.jaccard_distance(set(tokens1), set(tokens3))\n",
    "#jd_sent_1_4 = nltk.jaccard_distance(set(tokens1), set(tokens4))\n",
    "#jd_sent_1_5 = nltk.jaccard_distance(set(tokens1), set(tokens5))\n",
    " \n",
    "print(jd_sent_1_2, \"Jaccard Distance between tokens1 and tokens2 with ngram 3\")\n",
    "print(jd_sent_1_3, \"Jaccard Distance between tokens1 and tokens3 with ngram 3\")\n",
    "print(jd_sent_1_4, \"Jaccard Distance between tokens1 and tokens4 with ngram 3\")\n",
    "print(jd_sent_1_5, \"Jaccard Distance between tokens1 and tokens5 with ngram 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing which algorithm to use all depends on what you want to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us examine the example we have seen in the course, and use Jackards on items (words) as opposed to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'&', 'T', 'AT'} tokens1\n",
      "{'&', 'T', 'Corporation', 'AT'} tokens2\n",
      "{'IBM', 'Corporation'} tokens3\n",
      "----------\n",
      "12 Edit Distance between AT&T and AT&T Corporation\n",
      "15 Edit Distance between AT&T and IBM Corporation\n",
      "4 Edit Distance between AT&T Corporation and IBM Corporation\n",
      "----------\n",
      "0.25 Jaccard Distance between AT&T and AT&T Corporation\n",
      "1.0 Jaccard Distance between AT&T and IBM Corporation\n",
      "0.8 Jaccard Distance between AT&T Corporation and IBM Corporation\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "company1 = \"AT&T\"\n",
    "company2 = \"AT&T Corporation\"\n",
    "company3 = \"IBM Corporation\"\n",
    "\n",
    "tokens1 = set(nltk.word_tokenize(company1))\n",
    "tokens2 = set(nltk.word_tokenize(company2))\n",
    "tokens3 = set(nltk.word_tokenize(company3))\n",
    "\n",
    "print(tokens1,\"tokens1\")\n",
    "print(tokens2,\"tokens2\")\n",
    "print(tokens3,\"tokens3\")\n",
    "\n",
    "print(\"----------\")\n",
    "ed_company_1_2 = nltk.edit_distance(company1, company2)\n",
    "ed_company_1_3 = nltk.edit_distance(company1, company3)\n",
    "ed_company_2_3 = nltk.edit_distance(company2, company3)\n",
    "\n",
    "print(ed_company_1_2, \"Edit Distance between AT&T and AT&T Corporation\")\n",
    "print(ed_company_1_3, \"Edit Distance between AT&T and IBM Corporation\")\n",
    "print(ed_company_2_3, \"Edit Distance between AT&T Corporation and IBM Corporation\")\n",
    "\n",
    "jd_company_1_2 = nltk.jaccard_distance(tokens1, tokens2)\n",
    "jd_company_1_3 = nltk.jaccard_distance(tokens1, tokens3)\n",
    "jd_company_2_3 = nltk.jaccard_distance(tokens2, tokens3)\n",
    "\n",
    "print(\"----------\")\n",
    "print(jd_company_1_2, \"Jaccard Distance between AT&T and AT&T Corporation\")\n",
    "print(jd_company_1_3, \"Jaccard Distance between AT&T and IBM Corporation\")\n",
    "print(jd_company_2_3, \"Jaccard Distance between AT&T Corporation and IBM Corporation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that using edit distances provides us with the wrong answer compared with the case where we apply jaccard similarity on items (tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - 3/4 = 0,25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
