{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini projet Qualité de Données : Détections des doublons\n",
    "## ***Christophe COMPAIN / Sander COHEN***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif et Données Disponibles\n",
    "L'objectif du projet est d'identifier les logiciels vendus sur les deux plateformes.\n",
    "Pour ce faire, nous disposons des données pour chacune des plateformes isolément, respectivement dans les fichiers ***Company1.csv*** et ***Company2.csv***. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages, Variables Globales et import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ccompain/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ccompain/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"D:\\\\OneDrive - Université Paris-Dauphine\\\\Bureau\\\\Cours Master\\\\12-Qualité de Données\\\\\\Projet\\\\mini-projet\\\\\"\n",
    "path = \"/Users/ccompain/Documents/code/Dauphine/MasterIASD_prepa_data/mini-projet/github/\"\n",
    "#file1= \"Data\\\\Company1.csv\" #\"SampleData\\\\Sample_Company1.csv\"\n",
    "file1 = \"Data/Company1.csv\"\n",
    "#file2= \"Data\\\\Company2.csv\" #\"SampleData\\\\Sample_Company2.csv\"\n",
    "file2 = \"Data/Company1.csv\"\n",
    "#real= \"Data\\\\Ground_truth_mappings.csv\" #\"SampleData\\\\Sample_Groud_truth_mappings.csv\"\n",
    "real= \"Data/Ground_truth_mappings.csv\" #\"SampleData\\\\Sample_Groud_truth_mappings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "company1 = pd.read_csv(path+file1, encoding = \"ISO-8859-1\")\n",
    "company2 = pd.read_csv(path+file2, encoding = \"ISO-8859-1\")\n",
    "ground_truth_matches = pd.read_csv(path+real, encoding = \"ISO-8859-1\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspects généraux"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           id                                              title  \\\n0  b000jz4hqo    clickart 950 000 - premier image pack (dvd-rom)   \n1  b0006zf55o   ca international - arcserve lap/desktop oem 30pk   \n2  b00004tkvy   noah's ark activity center (jewel case ages 3-8)   \n3  b000g80lqo  peachtree by sage premium accounting for nonpr...   \n4  b0006se5bq                            singing coach unlimited   \n\n                                         description  \\\n0                                                NaN   \n1  oem arcserve backup v11.1 win 30u for laptops ...   \n2                                                NaN   \n3  peachtree premium accounting for nonprofits 20...   \n4  singing coach unlimited - electronic learning ...   \n\n                manufacturer   price  \n0                 broderbund    0.00  \n1        computer associates    0.00  \n2         victory multimedia    0.00  \n3              sage software  599.99  \n4  carry-a-tune technologies   99.99  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>description</th>\n      <th>manufacturer</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b000jz4hqo</td>\n      <td>clickart 950 000 - premier image pack (dvd-rom)</td>\n      <td>NaN</td>\n      <td>broderbund</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b0006zf55o</td>\n      <td>ca international - arcserve lap/desktop oem 30pk</td>\n      <td>oem arcserve backup v11.1 win 30u for laptops ...</td>\n      <td>computer associates</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b00004tkvy</td>\n      <td>noah's ark activity center (jewel case ages 3-8)</td>\n      <td>NaN</td>\n      <td>victory multimedia</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b000g80lqo</td>\n      <td>peachtree by sage premium accounting for nonpr...</td>\n      <td>peachtree premium accounting for nonprofits 20...</td>\n      <td>sage software</td>\n      <td>599.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b0006se5bq</td>\n      <td>singing coach unlimited</td>\n      <td>singing coach unlimited - electronic learning ...</td>\n      <td>carry-a-tune technologies</td>\n      <td>99.99</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "id              1363\ntitle           1363\ndescription     1248\nmanufacturer    1363\nprice           1363\ndtype: int64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           id                                              title  \\\n0  b000jz4hqo    clickart 950 000 - premier image pack (dvd-rom)   \n1  b0006zf55o   ca international - arcserve lap/desktop oem 30pk   \n2  b00004tkvy   noah's ark activity center (jewel case ages 3-8)   \n3  b000g80lqo  peachtree by sage premium accounting for nonpr...   \n4  b0006se5bq                            singing coach unlimited   \n\n                                         description  \\\n0                                                NaN   \n1  oem arcserve backup v11.1 win 30u for laptops ...   \n2                                                NaN   \n3  peachtree premium accounting for nonprofits 20...   \n4  singing coach unlimited - electronic learning ...   \n\n                manufacturer   price  \n0                 broderbund    0.00  \n1        computer associates    0.00  \n2         victory multimedia    0.00  \n3              sage software  599.99  \n4  carry-a-tune technologies   99.99  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>description</th>\n      <th>manufacturer</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b000jz4hqo</td>\n      <td>clickart 950 000 - premier image pack (dvd-rom)</td>\n      <td>NaN</td>\n      <td>broderbund</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b0006zf55o</td>\n      <td>ca international - arcserve lap/desktop oem 30pk</td>\n      <td>oem arcserve backup v11.1 win 30u for laptops ...</td>\n      <td>computer associates</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b00004tkvy</td>\n      <td>noah's ark activity center (jewel case ages 3-8)</td>\n      <td>NaN</td>\n      <td>victory multimedia</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b000g80lqo</td>\n      <td>peachtree by sage premium accounting for nonpr...</td>\n      <td>peachtree premium accounting for nonprofits 20...</td>\n      <td>sage software</td>\n      <td>599.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b0006se5bq</td>\n      <td>singing coach unlimited</td>\n      <td>singing coach unlimited - electronic learning ...</td>\n      <td>carry-a-tune technologies</td>\n      <td>99.99</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "id              1363\ntitle           1363\ndescription     1248\nmanufacturer    1363\nprice           1363\ndtype: int64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   idCompany1            idCompany2\n0  b000jz4hqo  18441480711193821750\n1  b00004tkvy  18441110047404795849\n2  b000g80lqo  18441188461196475272\n3  b0006se5bq  18428750969726461849\n4  b00021xhzw  18430621475529168165",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idCompany1</th>\n      <th>idCompany2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b000jz4hqo</td>\n      <td>18441480711193821750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b00004tkvy</td>\n      <td>18441110047404795849</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b000g80lqo</td>\n      <td>18441188461196475272</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b0006se5bq</td>\n      <td>18428750969726461849</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b00021xhzw</td>\n      <td>18430621475529168165</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "idCompany1    1300\nidCompany2    1300\ndtype: int64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_matches.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Top manufacturers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "manufacturer\nadobe                   87\nencore software         76\ntopics entertainment    73\nencore                  62\nmicrosoft               58\naspyr media             27\napple                   26\nfogware publishing      19\nintuit                  18\nName: id, dtype: int64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1.groupby('manufacturer')['id'].count().sort_values(ascending=False).head(9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "manufacturer\nadobe                   87\nencore software         76\ntopics entertainment    73\nencore                  62\nmicrosoft               58\naspyr media             27\napple                   26\nfogware publishing      19\nintuit                  18\nName: id, dtype: int64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2.groupby('manufacturer')['id'].count().sort_values(ascending=False).head(9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation d'un premier duplicat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b00004tkvy</td>\n",
       "      <td>noah's ark activity center (jewel case ages 3-8)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>victory multimedia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             title description  \\\n",
       "2  b00004tkvy  noah's ark activity center (jewel case ages 3-8)         NaN   \n",
       "\n",
       "         manufacturer  price  \n",
       "2  victory multimedia    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1[company1.id == ground_truth_matches.idCompany1[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1881</td>\n",
       "      <td>18441110047404795849</td>\n",
       "      <td>the beginners bible: noah's ark activity cente...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               name  \\\n",
       "1881  18441110047404795849  the beginners bible: noah's ark activity cente...   \n",
       "\n",
       "     description manufacturer price  \n",
       "1881         NaN          NaN  9.95  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2[company2.id == ground_truth_matches.idCompany2[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Récupération d'une base de stop_words pour nettoyage des descriptions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "stop_words.update([\"r\",\"v\",\"software\",\"entertainment\",\"inc\",\"usa\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fonction de tokenization et nettoyage de chaine de caractères\n",
    " - suppression des caractères non alpha\n",
    " - conversion majuscule vers minuscule\n",
    " - remplacement d'abbréviations communes\n",
    " - lemmatisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def prep(texte):\n",
    "    #suppression des caracteres non alphanumériques + tout en minuscule\n",
    "    texte = re.sub(\"[^a-zA-Z0-9_]\", \" \",str(texte)).lower()\n",
    "    #remplacement de mots\n",
    "    texte = texte.replace(\"professional\", \"pro\").replace(\" upg \",\" upgrade \").replace(\" dlx \",\" deluxe \")\n",
    "    #tokenization par mot\n",
    "    tokens = nltk.word_tokenize(texte)\n",
    "    #supreesion des stopwords\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words]\n",
    "#    # Stemming\n",
    "#    texte = [nltk.stem.SnowballStemmer('english').stem(w) for w in filtered_tokens]\n",
    "    # Lemmatization\n",
    "    texte = [nltk.stem.WordNetLemmatizer().lemmatize(w) for w in filtered_tokens]\n",
    "    #remise sous forme d'une string\n",
    "    return \" \".join(texte)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fonction de normalisation des prix\n",
    " - suppression caractères non-alpha\n",
    " - conversion en minuscule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def retreatprice(texte):\n",
    "    #suppression des caracteres non alphanumériques + tout en minuscule\n",
    "    return float(re.sub(\"[^0-9.]\", \" \",str(texte)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pre-Processing des 2 dataframes\n",
    " - Renommage des colonnes\n",
    " - Imputation des \"na\"\n",
    " - Traitement des prix\n",
    " - Construction d'une colonne \"full data\" contenant le titre et le manufacturer sur laquelle la fonction \"prep\" est appliquée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "company1['Company']=\"company1\"\n",
    "company1=company1.rename(columns={\"title\": \"name\"})\n",
    "company1['name'] = company1['name'].fillna(' ')\n",
    "company1['manufacturer'] = company1['manufacturer'].fillna(' ')\n",
    "company1['description'] = company1['description'].fillna(' ')\n",
    "company1['price'] = company1['price'].fillna(' ')\n",
    "company1['price_retreat'] = company1['price'].apply(retreatprice)\n",
    "company1['full data']=company1['manufacturer'].apply(prep) + ' ' + company1['name'].apply(prep) # + ' ' + company1['description'].apply(prep)\n",
    "\n",
    "company2['Company']=\"company2\"\n",
    "company2=company2.rename(columns={\"title\": \"name\"})\n",
    "company2['name'] = company2['name'].fillna(' ')\n",
    "company2['manufacturer'] = company2['manufacturer'].fillna(' ')\n",
    "company2['description'] = company2['description'].fillna(' ')\n",
    "company2['price'] = company2['price'].fillna(' ')\n",
    "company2['price_retreat'] = company2['price'].apply(retreatprice)\n",
    "company2['full data']=company2['manufacturer'].apply(prep) + ' ' + company2['name'].apply(prep) # + ' ' + company2['description'].apply(prep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Création d'un Dataframe \"corpus\" contenant les données de company1 et company2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2726"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.concat([company1, company2],sort=False,ignore_index=True)\n",
    "#corpus.reset_index(drop=True)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "              id                                   name  \\\n2721  b000cs3s2c     flash remoting 1 alp ret eng cd 2u   \n2722  b00005bigp                                 shapes   \n2723  b000h1df7w  dragon naturally speaking standard v9   \n2724  b000p9cr66                           mediarecover   \n2725  b000j588g4                    photo explosion 3.0   \n\n                                            description  \\\n2721  - marketing information: macromedia flash remo...   \n2722                                                      \n2723  dragon naturallyspeaking 9 (standard edition) ...   \n2724  mediarecover gives you the ability to recover ...   \n2725                                photo explosion 3.0   \n\n                    manufacturer    price   Company  price_retreat  \\\n2721                       adobe  3314.09  company2        3314.09   \n2722                 school zone     9.99  company2           9.99   \n2723  nuance communications inc.    99.99  company2          99.99   \n2724             aladdin systems    29.99  company2          29.99   \n2725            nova development    29.99  company2          29.99   \n\n                                              full data  \n2721           adobe flash remoting 1 alp ret eng cd 2u  \n2722                                  school zone shape  \n2723  nuance communication dragon naturally speaking...  \n2724                        aladdin system mediarecover  \n2725               nova development photo explosion 3 0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>description</th>\n      <th>manufacturer</th>\n      <th>price</th>\n      <th>Company</th>\n      <th>price_retreat</th>\n      <th>full data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2721</th>\n      <td>b000cs3s2c</td>\n      <td>flash remoting 1 alp ret eng cd 2u</td>\n      <td>- marketing information: macromedia flash remo...</td>\n      <td>adobe</td>\n      <td>3314.09</td>\n      <td>company2</td>\n      <td>3314.09</td>\n      <td>adobe flash remoting 1 alp ret eng cd 2u</td>\n    </tr>\n    <tr>\n      <th>2722</th>\n      <td>b00005bigp</td>\n      <td>shapes</td>\n      <td></td>\n      <td>school zone</td>\n      <td>9.99</td>\n      <td>company2</td>\n      <td>9.99</td>\n      <td>school zone shape</td>\n    </tr>\n    <tr>\n      <th>2723</th>\n      <td>b000h1df7w</td>\n      <td>dragon naturally speaking standard v9</td>\n      <td>dragon naturallyspeaking 9 (standard edition) ...</td>\n      <td>nuance communications inc.</td>\n      <td>99.99</td>\n      <td>company2</td>\n      <td>99.99</td>\n      <td>nuance communication dragon naturally speaking...</td>\n    </tr>\n    <tr>\n      <th>2724</th>\n      <td>b000p9cr66</td>\n      <td>mediarecover</td>\n      <td>mediarecover gives you the ability to recover ...</td>\n      <td>aladdin systems</td>\n      <td>29.99</td>\n      <td>company2</td>\n      <td>29.99</td>\n      <td>aladdin system mediarecover</td>\n    </tr>\n    <tr>\n      <th>2725</th>\n      <td>b000j588g4</td>\n      <td>photo explosion 3.0</td>\n      <td>photo explosion 3.0</td>\n      <td>nova development</td>\n      <td>29.99</td>\n      <td>company2</td>\n      <td>29.99</td>\n      <td>nova development photo explosion 3 0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recherche des mots \"unique\" dans le \"full data\" pour réduire l'espace de recherche"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = corpus['full data'].str.split(expand=True).stack().value_counts()\n",
    "stop_unique = set(allwords[allwords==1].index)\n",
    "\n",
    "def prep2(texte):\n",
    "    tokens = nltk.word_tokenize(texte)\n",
    "    #supreesion des stopwords\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_unique]\n",
    "    #remise sous forme d'une string\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "company1['full data']=company1['full data'].apply(prep2)\n",
    "company2['full data']=company2['full data'].apply(prep2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fonction d'ientification des doublons\n",
    " - après quelques essais pas forcément concluants utilisants la distance de Jacquard, nous avons décidés d'expérimenter TF-IDF\n",
    " - TF : Term-Frequency => Renvoie la fréquence de chaque mot dans le corpus\n",
    " - IDF : Inverse-Data-Frequency => Calcule du poids des mots\n",
    " - le TF-IDF score sera le produit des 2 précédentes valeurs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction tfidf\n",
    "def filtre_tfidf(corpus, ngram, max_df,sim_lim, stop):\n",
    "    global ground_truth_matches,number_of_matches, matches, matches_df\n",
    "    start = time.process_time()\n",
    "    new_number_of_matches = 0\n",
    "    new_matches=[]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram, max_df=max_df,sublinear_tf=True,stop_words=[stop]) \n",
    "    vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "\n",
    "    for i in range(len(company1_light)):\n",
    "        #try :  \n",
    "        price1 = float(company1_light.iloc[i,6]) \n",
    "        #except : \n",
    "        #    price1 = 0\n",
    "        #tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "        for j in range(len(company2_light)):\n",
    "            #try :  \n",
    "            price2 = float(company2_light.iloc[j,6]) \n",
    "            #except : \n",
    "            #    price2 = 0\n",
    "            #tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "            #ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "            #jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "            if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "                try :\n",
    "                    similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "                except : \n",
    "                    similarity = 0\n",
    "                if  similarity > sim_lim: #or jd_ng1_ng2_name<0.2 :# or name_score<=1) :\n",
    "                    new_number_of_matches = new_number_of_matches +1\n",
    "                    new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "\n",
    "    if new_number_of_matches>0:\n",
    "        print(\"New matches: {}\".format(new_number_of_matches))\n",
    "        number_of_matches= number_of_matches + new_number_of_matches\n",
    "        print(\"Total matches: {}\".format(number_of_matches))\n",
    "        if matches== []:\n",
    "            matches = new_matches \n",
    "            matches_df = pd.DataFrame(matches)\n",
    "            matches_df.columns= ['idCompany1','idCompany2']\n",
    "        else:\n",
    "            new_matches_df = pd.DataFrame(new_matches)\n",
    "            new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "            matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True).drop_duplicates()\n",
    "\n",
    "        diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "        true_positives = diff_df[diff_df.Exist=='both']\n",
    "        false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "        false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "        print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "        print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "        print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "        precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "        print(\"Precision: {}\".format(precision))\n",
    "        recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "        print(\"Recall: {}\".format(recall))\n",
    "        try :\n",
    "            f_measure = 2*(precision*recall)/(precision+recall)\n",
    "            print(\"F measure: {}\".format(f_measure))\n",
    "        except:\n",
    "            print(\"F measure not calculable\")\n",
    "    else:\n",
    "        print(\"No new match\")\n",
    "    end = time.process_time()\n",
    "    print(\"Processing time: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "company1_light=company1\n",
    "company2_light=company2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft with ngram=(1,2)\n",
      "New matches: 108\n",
      "Total matches: 108\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on uint64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-53-4d066f66b180>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mcorpus\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcompany1_light\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcompany2_light\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msort\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"{} with ngram=(1,{})\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltre\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmax_ngram\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m         \u001B[0mfiltre_tfidf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcorpus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmax_ngram\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.1\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0;36m0.6\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiltre\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\" \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-51-319e71e19a5d>\u001B[0m in \u001B[0;36mfiltre_tfidf\u001B[0;34m(corpus, ngram, max_df, sim_lim, stop)\u001B[0m\n\u001B[1;32m     47\u001B[0m             \u001B[0mmatches_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmatches_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_matches_df\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msort\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop_duplicates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m         \u001B[0mdiff_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmerge\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mground_truth_matches\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmatches_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'outer'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindicator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'Exist'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0mtrue_positives\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdiff_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdiff_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExist\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;34m'both'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0mfalse_positives\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdiff_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdiff_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExist\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;34m'right_only'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36mmerge\u001B[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[1;32m     72\u001B[0m     \u001B[0mvalidate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m ) -> \"DataFrame\":\n\u001B[0;32m---> 74\u001B[0;31m     op = _MergeOperation(\n\u001B[0m\u001B[1;32m     75\u001B[0m         \u001B[0mleft\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m         \u001B[0mright\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[1;32m    670\u001B[0m         \u001B[0;31m# validate the merge keys dtypes. We may need to coerce\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m         \u001B[0;31m# to avoid incompatible dtypes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 672\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_coerce_merge_keys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    673\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    674\u001B[0m         \u001B[0;31m# If argument passed to validate,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m_maybe_coerce_merge_keys\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1191\u001B[0m                     \u001B[0minferred_right\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstring_types\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0minferred_left\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstring_types\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1192\u001B[0m                 ):\n\u001B[0;32m-> 1193\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1194\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1195\u001B[0m             \u001B[0;31m# datetimelikes must match exactly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: You are trying to merge on uint64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "#boucle sur les big manufacturer\n",
    "big_manufacturer_list=[\"microsoft\",\"apple\",\"encore\",\"adobe\",\"punch\",\"topic\",\"aspyr\",\"sony\",\"webroot\"]\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "matches_df=[]\n",
    "for filtre in big_manufacturer_list :\n",
    "    for max_ngram in [2,1]:\n",
    "        try :\n",
    "            company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "            company2_light=company2[~company2.id.isin(matches_df.idCompany2)]    \n",
    "        except : \n",
    "            company1_light=company1\n",
    "            company2_light=company2        \n",
    "        company1_light = company1_light[company1_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "        company2_light = company2_light[company2_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "        corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "        print(\"{} with ngram=(1,{})\".format(filtre,max_ngram))\n",
    "        filtre_tfidf(corpus, (1,max_ngram), 0.1 ,0.6, filtre)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##boucle sur les autres noms\n",
    "for max_ngram in [3,2,1]:\n",
    "    company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "    company2_light=company2[~company2.id.isin(matches_df.idCompany2)]    \n",
    "    corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "    print(\"Other entries with ngram=(1,{})\".format(max_ngram))\n",
    "    filtre_tfidf(corpus, (1,max_ngram), 0.01 ,0.5, \"\")\n",
    "    print(\" \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_false_negatives =false_negatives.merge(corpus.loc[corpus['Company'] == 'company1']\n",
    "                                            .drop(['Company','name','manufacturer'], inplace=False, axis=1)\n",
    "                                            .rename(columns = {'id': 'idCompany1','description': 'descr1',\n",
    "                                                               'price': 'price1','full data': 'full data1'}\n",
    "                                                    , inplace = False)\n",
    "                                            , how='inner', on='idCompany1').merge(corpus.loc[corpus['Company'] == 'company2']\n",
    "                                                                                  .drop(['Company','name','manufacturer'], inplace=False, axis=1)\n",
    "                                                                                  .rename(columns = {'id': 'idCompany2', \n",
    "                                                                                                     'description': 'descr2', \n",
    "                                                                                                     'price': 'price2', \n",
    "                                                                                                     'full data': 'full data2'}, inplace = False)\n",
    "                                                                                  , how='inner', on='idCompany2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_false_positives =false_positives.merge(corpus.loc[corpus['Company'] == 'company1']\n",
    "                                            .drop(['Company','name','manufacturer'], inplace=False, axis=1)\n",
    "                                            .rename(columns = {'id': 'idCompany1','description': 'descr1',\n",
    "                                                               'price': 'price1','full data': 'full data1'}\n",
    "                                                    , inplace = False)\n",
    "                                            , how='inner', on='idCompany1').merge(corpus.loc[corpus['Company'] == 'company2']\n",
    "                                                                                  .drop(['Company','name','manufacturer'], inplace=False, axis=1)\n",
    "                                                                                  .rename(columns = {'id': 'idCompany2', \n",
    "                                                                                                     'description': 'descr2', \n",
    "                                                                                                     'price': 'price2', \n",
    "                                                                                                     'full data': 'full data2'}, inplace = False)\n",
    "                                                                                  , how='inner', on='idCompany2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_false_positives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "base_false_negatives"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}