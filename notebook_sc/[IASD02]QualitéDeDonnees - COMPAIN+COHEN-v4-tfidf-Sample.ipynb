{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini projet Qualité de Données : Détections des doublons\n",
    "## ***Christophe COMPAIN / Sander COHEN***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif et Données Disponibles\n",
    "L'objectif du projet est d'identifier les logiciels vendus sur les deux plateformes.\n",
    "\n",
    "Pour ce faire, nous disposons des données pour chacune des plateformes isolément, respectivement dans les fichiers ***Company1.csv*** et ***Company2.csv***. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages, Variables Globales et import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\scohe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\scohe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\OneDrive - Université Paris-Dauphine\\\\Bureau\\\\Cours Master\\\\12-Qualité de Données\\\\\\Projet\\\\mini-projet\\\\\"\n",
    "file1= \"SampleData\\\\Sample_Company1.csv\" ##\"Data\\\\Company1.csv\" #\"SampleData\\\\Sample_Company1.csv\"\n",
    "file2= \"SampleData\\\\Sample_Company2.csv\" ##\"Data\\\\Company2.csv\" #\"SampleData\\\\Sample_Company2.csv\"\n",
    "real= \"SampleData\\\\Sample_Groud_truth_mappings.csv\" ##\"Data\\\\Ground_truth_mappings.csv\" #\"SampleData\\\\Sample_Groud_truth_mappings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "company1 = pd.read_csv(path+file1, encoding = \"ISO-8859-1\")\n",
    "company2 = pd.read_csv(path+file2, encoding = \"ISO-8859-1\")\n",
    "ground_truth_matches = pd.read_csv(path+real, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b0000aka82</td>\n",
       "      <td>studyworks! teaching pro: middle school math &amp;...</td>\n",
       "      <td>studyworks teaching pro middle school math &amp; s...</td>\n",
       "      <td>global software publishing</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b000bnb72g</td>\n",
       "      <td>movies on psp</td>\n",
       "      <td>x-zoom movies on psp is the first commercial v...</td>\n",
       "      <td>x-oom</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b0002e3g6o</td>\n",
       "      <td>eastwest bsendorfer 290 grand piano virtual in...</td>\n",
       "      <td>the 5-star awarded pmi bdorfer 290 is simply t...</td>\n",
       "      <td>eastwest</td>\n",
       "      <td>199.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b00008ajjc</td>\n",
       "      <td>passwords plus 1.0</td>\n",
       "      <td>passwords plus stores all your personal inform...</td>\n",
       "      <td>dataviz</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b0006g2wke</td>\n",
       "      <td>microsoft licenses project svr sa govt (h2200301)</td>\n",
       "      <td>microsoft project server win32 english softwar...</td>\n",
       "      <td>microsoft licenses</td>\n",
       "      <td>3601.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0  b0000aka82  studyworks! teaching pro: middle school math &...   \n",
       "1  b000bnb72g                                      movies on psp   \n",
       "2  b0002e3g6o  eastwest bsendorfer 290 grand piano virtual in...   \n",
       "3  b00008ajjc                                 passwords plus 1.0   \n",
       "4  b0006g2wke  microsoft licenses project svr sa govt (h2200301)   \n",
       "\n",
       "                                         description  \\\n",
       "0  studyworks teaching pro middle school math & s...   \n",
       "1  x-zoom movies on psp is the first commercial v...   \n",
       "2  the 5-star awarded pmi bdorfer 290 is simply t...   \n",
       "3  passwords plus stores all your personal inform...   \n",
       "4  microsoft project server win32 english softwar...   \n",
       "\n",
       "                 manufacturer    price  \n",
       "0  global software publishing    29.99  \n",
       "1                       x-oom     0.00  \n",
       "2                    eastwest   199.95  \n",
       "3                     dataviz    29.99  \n",
       "4          microsoft licenses  3601.40  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12244614697089679523</td>\n",
       "      <td>production prem cs3 mac upgrad</td>\n",
       "      <td>adobe cs3 production premium mac upgrade from ...</td>\n",
       "      <td>adobe software</td>\n",
       "      <td>805.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5781318040297863663</td>\n",
       "      <td>ipswitch wd-1000-0900 ws_ftp pro 9 sdk w/ ws_f...</td>\n",
       "      <td>no description available</td>\n",
       "      <td>ipswitch</td>\n",
       "      <td>325.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9949258255997064102</td>\n",
       "      <td>money prem 2007 cd minibox</td>\n",
       "      <td>money premium 2007 win32 english north america...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>63.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9761533219806554318</td>\n",
       "      <td>adobe indesign cs3 for mac upgrade</td>\n",
       "      <td>system requirements powerpc g4 or g5 or intel ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>18226456193742595288</td>\n",
       "      <td>bamboo technology llc vault360 combo</td>\n",
       "      <td>capitalizing on the popularity of the ipod psp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               name  \\\n",
       "0  12244614697089679523                     production prem cs3 mac upgrad   \n",
       "1   5781318040297863663  ipswitch wd-1000-0900 ws_ftp pro 9 sdk w/ ws_f...   \n",
       "2   9949258255997064102                         money prem 2007 cd minibox   \n",
       "3   9761533219806554318                 adobe indesign cs3 for mac upgrade   \n",
       "4  18226456193742595288               bamboo technology llc vault360 combo   \n",
       "\n",
       "                                         description    manufacturer   price  \n",
       "0  adobe cs3 production premium mac upgrade from ...  adobe software  805.99  \n",
       "1                           no description available        ipswitch  325.51  \n",
       "2  money premium 2007 win32 english north america...       microsoft   63.99  \n",
       "3  system requirements powerpc g4 or g5 or intel ...             NaN  205.99  \n",
       "4  capitalizing on the popularity of the ipod psp...             NaN   24.58  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idCompany1</th>\n",
       "      <th>idCompany2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b0002ibev4</td>\n",
       "      <td>1887899244694755891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b0007lw22g</td>\n",
       "      <td>18398718226932431716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b000ofnri8</td>\n",
       "      <td>12244614697089679523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b0007d8r5k</td>\n",
       "      <td>13775362651326388438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b00099qrok</td>\n",
       "      <td>9755705822363275907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idCompany1            idCompany2\n",
       "0  b0002ibev4   1887899244694755891\n",
       "1  b0007lw22g  18398718226932431716\n",
       "2  b000ofnri8  12244614697089679523\n",
       "3  b0007d8r5k  13775362651326388438\n",
       "4  b00099qrok   9755705822363275907"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_matches.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation d'un premier duplicat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>b0007lw22g</td>\n",
       "      <td>apple ilife '06 (mac dvd) [older version]</td>\n",
       "      <td>ilife '06 is the easiest way to make the most ...</td>\n",
       "      <td>apple computer</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                      title  \\\n",
       "32  b0007lw22g  apple ilife '06 (mac dvd) [older version]   \n",
       "\n",
       "                                          description    manufacturer  price  \n",
       "32  ilife '06 is the easiest way to make the most ...  apple computer   79.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1[company1.id == ground_truth_matches.idCompany1[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>18398718226932431716</td>\n",
       "      <td>ilife '06 mac - apple - ma166z/a</td>\n",
       "      <td>ilife '06 the must-have update to apple's awar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.8 gbp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                              name  \\\n",
       "46  18398718226932431716  ilife '06 mac - apple - ma166z/a   \n",
       "\n",
       "                                          description manufacturer     price  \n",
       "46  ilife '06 the must-have update to apple's awar...          NaN  47.8 gbp  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2[company2.id == ground_truth_matches.idCompany2[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))  \n",
    "stop_words.update(\"r\")\n",
    "\n",
    "def prep(texte):\n",
    "    #suppression des caracteres non alphanumériques + tout en minuscule\n",
    "    texte = re.sub(\"[^a-zA-Z0-9_]\", \" \",str(texte)).lower()\n",
    "    #tokenization par mot\n",
    "    tokens = nltk.word_tokenize(texte)\n",
    "    #supreesion des stopwords\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words]\n",
    "#    # Stemming\n",
    "#    texte = [nltk.stem.SnowballStemmer('english').stem(w) for w in filtered_tokens]\n",
    "    # Lemmatization\n",
    "    texte = [nltk.stem.WordNetLemmatizer().lemmatize(w) for w in filtered_tokens]\n",
    "    #remise sous forme d'une string\n",
    "    return \" \".join(texte)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>Company</th>\n",
       "      <th>full data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>11463298814554093369</td>\n",
       "      <td>podmaxx '07 eb carlson</td>\n",
       "      <td>key features: burn music from your ipod create...</td>\n",
       "      <td></td>\n",
       "      <td>29.99</td>\n",
       "      <td>company2</td>\n",
       "      <td>podmaxx 07 eb carlson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>9255722138583214734</td>\n",
       "      <td>microsoft office outlook 2007</td>\n",
       "      <td>key features: manages time and info works with...</td>\n",
       "      <td></td>\n",
       "      <td>109.95</td>\n",
       "      <td>company2</td>\n",
       "      <td>microsoft office outlook 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>5976779863499710865</td>\n",
       "      <td>apple software t9164ll/a logic express 6</td>\n",
       "      <td>logic express offers the same flexibility reli...</td>\n",
       "      <td>apple software</td>\n",
       "      <td>219</td>\n",
       "      <td>company2</td>\n",
       "      <td>apple software apple software t9164ll logic ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>10621416214836586442</td>\n",
       "      <td>punch software 41100 punch! home design archit...</td>\n",
       "      <td>architectural series 18 provides innovative ne...</td>\n",
       "      <td>punch software</td>\n",
       "      <td>118.99</td>\n",
       "      <td>company2</td>\n",
       "      <td>punch software punch software 41100 punch home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>13778334917246964953</td>\n",
       "      <td>weekly reader preparing for kindergarten 2008 ...</td>\n",
       "      <td>key features: interactive questions encourages...</td>\n",
       "      <td></td>\n",
       "      <td>19.99</td>\n",
       "      <td>company2</td>\n",
       "      <td>weekly reader preparing kindergarten 2008 pc ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               name  \\\n",
       "195  11463298814554093369                             podmaxx '07 eb carlson   \n",
       "196   9255722138583214734                      microsoft office outlook 2007   \n",
       "197   5976779863499710865           apple software t9164ll/a logic express 6   \n",
       "198  10621416214836586442  punch software 41100 punch! home design archit...   \n",
       "199  13778334917246964953  weekly reader preparing for kindergarten 2008 ...   \n",
       "\n",
       "                                           description    manufacturer  \\\n",
       "195  key features: burn music from your ipod create...                   \n",
       "196  key features: manages time and info works with...                   \n",
       "197  logic express offers the same flexibility reli...  apple software   \n",
       "198  architectural series 18 provides innovative ne...  punch software   \n",
       "199  key features: interactive questions encourages...                   \n",
       "\n",
       "      price   Company                                          full data  \n",
       "195   29.99  company2                              podmaxx 07 eb carlson  \n",
       "196  109.95  company2                      microsoft office outlook 2007  \n",
       "197     219  company2  apple software apple software t9164ll logic ex...  \n",
       "198  118.99  company2  punch software punch software 41100 punch home...  \n",
       "199   19.99  company2   weekly reader preparing kindergarten 2008 pc ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1['Company']=\"company1\"\n",
    "company1=company1.rename(columns={\"title\": \"name\"})\n",
    "company2['Company']=\"company2\"\n",
    "corpus = pd.concat([company1, company2],sort=False,ignore_index=True)\n",
    "corpus['name'] = corpus['name'].fillna(' ')\n",
    "corpus['manufacturer'] = corpus['manufacturer'].fillna(' ')\n",
    "corpus['description'] = corpus['description'].fillna(' ')\n",
    "corpus['full data']=corpus['manufacturer'].apply(prep) + ' ' + corpus['name'].apply(prep) # + ' ' + corpus['description'].apply(prep)#corpus['manufacturer'] + ' ' + corpus['name'] + ' ' + corpus['description']\n",
    "#corpus.reset_index(drop=True)\n",
    "len(corpus)\n",
    "corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' autodesk combustion 4 0 compositing software win compositing software'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['full data'][166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.10) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00301</th>\n",
       "      <th>00301 gov</th>\n",
       "      <th>02322</th>\n",
       "      <th>02322 ae</th>\n",
       "      <th>03871</th>\n",
       "      <th>03871 molpc</th>\n",
       "      <th>059</th>\n",
       "      <th>059 03871</th>\n",
       "      <th>05903871</th>\n",
       "      <th>06</th>\n",
       "      <th>...</th>\n",
       "      <th>ws_ftp</th>\n",
       "      <th>ws_ftp pro</th>\n",
       "      <th>x3</th>\n",
       "      <th>x3 upgrade</th>\n",
       "      <th>xp</th>\n",
       "      <th>xp 2000</th>\n",
       "      <th>xp mac</th>\n",
       "      <th>xp vista</th>\n",
       "      <th>yamaha</th>\n",
       "      <th>yamaha little</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00301  00301 gov  02322  02322 ae  03871  03871 molpc  059  059 03871  \\\n",
       "0      0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "1      0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "2      0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "3      0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "4      0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "..     ...        ...    ...       ...    ...          ...  ...        ...   \n",
       "195    0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "196    0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "197    0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "198    0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "199    0.0        0.0    0.0       0.0    0.0          0.0  0.0        0.0   \n",
       "\n",
       "     05903871   06  ...  ws_ftp  ws_ftp pro   x3  x3 upgrade   xp  xp 2000  \\\n",
       "0         0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "1         0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "2         0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "3         0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "4         0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "..        ...  ...  ...     ...         ...  ...         ...  ...      ...   \n",
       "195       0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "196       0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "197       0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "198       0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "199       0.0  0.0  ...     0.0         0.0  0.0         0.0  0.0      0.0   \n",
       "\n",
       "     xp mac  xp vista  yamaha  yamaha little  \n",
       "0       0.0       0.0     0.0            0.0  \n",
       "1       0.0       0.0     0.0            0.0  \n",
       "2       0.0       0.0     0.0            0.0  \n",
       "3       0.0       0.0     0.0            0.0  \n",
       "4       0.0       0.0     0.0            0.0  \n",
       "..      ...       ...     ...            ...  \n",
       "195     0.0       0.0     0.0            0.0  \n",
       "196     0.0       0.0     0.0            0.0  \n",
       "197     0.0       0.0     0.0            0.0  \n",
       "198     0.0       0.0     0.0            0.0  \n",
       "199     0.0       0.0     0.0            0.0  \n",
       "\n",
       "[200 rows x 1202 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "#feature_names\n",
    "#dense.shape #.head() 4589 rows × 12391 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 107\n",
      "Number of true positives: 90\n",
      "Number of false positives: 17\n",
      "Number of false negatives: 15\n",
      "Precision: 0.8411214953271028\n",
      "Recall: 0.8571428571428571\n",
      "F measure: 0.8490566037735849\n"
     ]
    }
   ],
   "source": [
    "##tfidf\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    try :  \n",
    "        price1 = float(company1.iloc[i,4]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    for j in range(len(company2)):\n",
    "        try :  \n",
    "            price2 = float(company2.iloc[j,4]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        if price1* price2 == 0:\n",
    "            price_ratio=1\n",
    "        else:\n",
    "            price_ratio =max(price1, price2)/min(price1, price2)\n",
    "        similarity = np.dot(dense[i],np.transpose(dense[len(company1)+j])).item(0)\n",
    "        if ((similarity > 0.25) and (price_ratio<2)):# or name_score<=1) :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b0006g2wke</td>\n",
       "      <td>microsoft licenses project svr sa govt (h2200301)</td>\n",
       "      <td>microsoft project server win32 english softwar...</td>\n",
       "      <td>microsoft licenses</td>\n",
       "      <td>3601.40</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>b000ofnri8</td>\n",
       "      <td>adobe creative suite cs3 production premium up...</td>\n",
       "      <td>note: this is the upgrade version of adobe cre...</td>\n",
       "      <td>adobe</td>\n",
       "      <td>799.00</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>b0006ma3bs</td>\n",
       "      <td>gmp data rescue - license ( 24300 )</td>\n",
       "      <td>data rescue pc and mac universal license by by...</td>\n",
       "      <td>global marketing partners</td>\n",
       "      <td>349.00</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>b000fncrto</td>\n",
       "      <td>cinescore professional soundtrack edition</td>\n",
       "      <td>sony cinescore is a breakthrough in profession...</td>\n",
       "      <td>sony pictures digital entertainment</td>\n",
       "      <td>249.95</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>b0006g2vk0</td>\n",
       "      <td>microsoft licenses word olp c (05903871)</td>\n",
       "      <td>model-059-03871 vendor- microsoft corporation ...</td>\n",
       "      <td>microsoft licenses</td>\n",
       "      <td>205.73</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b0002e3g6o</td>\n",
       "      <td>eastwest bsendorfer 290 grand piano virtual in...</td>\n",
       "      <td>the 5-star awarded pmi bdorfer 290 is simply t...</td>\n",
       "      <td>eastwest</td>\n",
       "      <td>199.95</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>b000jgf410</td>\n",
       "      <td>money premium 2007 win32 eng na mini box us on...</td>\n",
       "      <td>model- ms-cd19382wi vendor- microsoft corporat...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>118.46</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>b000om7diq</td>\n",
       "      <td>corel dvd moviefactory 6.0 plus</td>\n",
       "      <td>ulead dvd moviefactory 6 plus is the award-win...</td>\n",
       "      <td>corel</td>\n",
       "      <td>79.99</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>b000om7diq</td>\n",
       "      <td>corel dvd moviefactory 6.0 plus</td>\n",
       "      <td>ulead dvd moviefactory 6 plus is the award-win...</td>\n",
       "      <td>corel</td>\n",
       "      <td>79.99</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>b000qtu1ay</td>\n",
       "      <td>portfolio media kit be syst recovery 7.0 win s...</td>\n",
       "      <td>be sys recovery 7.0 win sbs ed media cd m/l</td>\n",
       "      <td>symantec</td>\n",
       "      <td>50.00</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>b000g3mer8</td>\n",
       "      <td>iplaymusic beginner guitar lessons for the mac...</td>\n",
       "      <td>iplaymusic's beginner guitar lessons is the fi...</td>\n",
       "      <td>iplaymusic</td>\n",
       "      <td>49.99</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>b000in8n30</td>\n",
       "      <td>hijack2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>navarre (software)</td>\n",
       "      <td>39.95</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>b000056b62</td>\n",
       "      <td>cook'n vegetarian</td>\n",
       "      <td>featuring recipes for tasty and healthful meat...</td>\n",
       "      <td>dvo enterprises</td>\n",
       "      <td>19.99</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>b000aa8796</td>\n",
       "      <td>aquarium 3-in-one collection (win/mac)</td>\n",
       "      <td>so vibrant and realistic you won&amp;rsquo;t belie...</td>\n",
       "      <td>encore software</td>\n",
       "      <td>19.99</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>b0007sxgmo</td>\n",
       "      <td>hoyle texas hold 'em poker (jewel case)</td>\n",
       "      <td>hoyle texas hold em puts your poker skills to ...</td>\n",
       "      <td>encore</td>\n",
       "      <td>9.99</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>b00099qrok</td>\n",
       "      <td>autodesk discreet combustion 4 ( windows )</td>\n",
       "      <td>combustion 4 offers an easy-to-use interface n...</td>\n",
       "      <td>autodesk</td>\n",
       "      <td>0.00</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               name  \\\n",
       "4   b0006g2wke  microsoft licenses project svr sa govt (h2200301)   \n",
       "46  b000ofnri8  adobe creative suite cs3 production premium up...   \n",
       "66  b0006ma3bs                gmp data rescue - license ( 24300 )   \n",
       "58  b000fncrto          cinescore professional soundtrack edition   \n",
       "22  b0006g2vk0           microsoft licenses word olp c (05903871)   \n",
       "2   b0002e3g6o  eastwest bsendorfer 290 grand piano virtual in...   \n",
       "13  b000jgf410  money premium 2007 win32 eng na mini box us on...   \n",
       "63  b000om7diq                    corel dvd moviefactory 6.0 plus   \n",
       "64  b000om7diq                    corel dvd moviefactory 6.0 plus   \n",
       "18  b000qtu1ay  portfolio media kit be syst recovery 7.0 win s...   \n",
       "56  b000g3mer8  iplaymusic beginner guitar lessons for the mac...   \n",
       "91  b000in8n30                                            hijack2   \n",
       "7   b000056b62                                  cook'n vegetarian   \n",
       "19  b000aa8796             aquarium 3-in-one collection (win/mac)   \n",
       "52  b0007sxgmo            hoyle texas hold 'em poker (jewel case)   \n",
       "11  b00099qrok         autodesk discreet combustion 4 ( windows )   \n",
       "\n",
       "                                          description  \\\n",
       "4   microsoft project server win32 english softwar...   \n",
       "46  note: this is the upgrade version of adobe cre...   \n",
       "66  data rescue pc and mac universal license by by...   \n",
       "58  sony cinescore is a breakthrough in profession...   \n",
       "22  model-059-03871 vendor- microsoft corporation ...   \n",
       "2   the 5-star awarded pmi bdorfer 290 is simply t...   \n",
       "13  model- ms-cd19382wi vendor- microsoft corporat...   \n",
       "63  ulead dvd moviefactory 6 plus is the award-win...   \n",
       "64  ulead dvd moviefactory 6 plus is the award-win...   \n",
       "18        be sys recovery 7.0 win sbs ed media cd m/l   \n",
       "56  iplaymusic's beginner guitar lessons is the fi...   \n",
       "91                                                NaN   \n",
       "7   featuring recipes for tasty and healthful meat...   \n",
       "19  so vibrant and realistic you won&rsquo;t belie...   \n",
       "52  hoyle texas hold em puts your poker skills to ...   \n",
       "11  combustion 4 offers an easy-to-use interface n...   \n",
       "\n",
       "                           manufacturer    price   Company  \n",
       "4                    microsoft licenses  3601.40  company1  \n",
       "46                                adobe   799.00  company1  \n",
       "66            global marketing partners   349.00  company1  \n",
       "58  sony pictures digital entertainment   249.95  company1  \n",
       "22                   microsoft licenses   205.73  company1  \n",
       "2                              eastwest   199.95  company1  \n",
       "13                            microsoft   118.46  company1  \n",
       "63                                corel    79.99  company1  \n",
       "64                                corel    79.99  company1  \n",
       "18                             symantec    50.00  company1  \n",
       "56                           iplaymusic    49.99  company1  \n",
       "91                   navarre (software)    39.95  company1  \n",
       "7                       dvo enterprises    19.99  company1  \n",
       "19                      encore software    19.99  company1  \n",
       "52                               encore     9.99  company1  \n",
       "11                             autodesk     0.00  company1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=1\n",
    "\n",
    "company1[company1['id'].isin(false_negatives['idCompany1'])].sort_values('price',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>9755705822363275907</td>\n",
       "      <td>autodesk combustion 4.0 compositing software -...</td>\n",
       "      <td>combustion 4.0 professional compositing softwa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>889</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12244614697089679523</td>\n",
       "      <td>production prem cs3 mac upgrad</td>\n",
       "      <td>adobe cs3 production premium mac upgrade from ...</td>\n",
       "      <td>adobe software</td>\n",
       "      <td>805.99</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>12250274471957898660</td>\n",
       "      <td>encore software 33027 - hoyle texas holdem (wi...</td>\n",
       "      <td>encore software 33027 : hoyle texas hold em le...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.44</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>17708766593513600591</td>\n",
       "      <td>corel corporation dvd movie factory 6 plus ret...</td>\n",
       "      <td>uleadÂ® dvd moviefactoryÂ® 6 plus is easy-to-u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.08</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9949258255997064102</td>\n",
       "      <td>money prem 2007 cd minibox</td>\n",
       "      <td>money premium 2007 win32 english north america...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>63.99</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>4377533611520192512</td>\n",
       "      <td>hijack2 identity and data security suite</td>\n",
       "      <td>prevent thieves from accessing any of your per...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.9</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>18391195855196917401</td>\n",
       "      <td>symantec 11859201 be sys recovery 7.0 win sbs ...</td>\n",
       "      <td>be sys recovery 7.0 win sbs ed media cd m/l</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.98</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>13255609368261584070</td>\n",
       "      <td>wingnuts 2: raina's revenge</td>\n",
       "      <td>system requirements: mac os x 10.4+ g4/g5/inte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.99</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>16814254064816255791</td>\n",
       "      <td>prosoft engineering data rescue universal license</td>\n",
       "      <td>do you have a corrupt hard drive or one that n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.34</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>18422068306669698354</td>\n",
       "      <td>microsoft h22-00301 gov open sa project svr w9...</td>\n",
       "      <td>gov open sa project svr w9x nt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.12</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>18446496383812786183</td>\n",
       "      <td>cookn vegetarian</td>\n",
       "      <td>the diet choice for many world cultures for mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.99</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>13804410937823415271</td>\n",
       "      <td>aquarium 3-in-one limited edition (win 95 98 m...</td>\n",
       "      <td>an amazing collection so vibrant and realistic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.95</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>9167720084838534914</td>\n",
       "      <td>sony media software cinescore soundtrack creat...</td>\n",
       "      <td>cinescore - professional soundtrack creation s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.95</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>18384557845547191313</td>\n",
       "      <td>east west bosendorfer 290</td>\n",
       "      <td>the pristine bosendorfer 290 piano library has...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.97</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>18365507478568694929</td>\n",
       "      <td>microsoft 059-03871 molpc word sa</td>\n",
       "      <td>molpc word sa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.78</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               name  \\\n",
       "66   9755705822363275907  autodesk combustion 4.0 compositing software -...   \n",
       "0   12244614697089679523                     production prem cs3 mac upgrad   \n",
       "81  12250274471957898660  encore software 33027 - hoyle texas holdem (wi...   \n",
       "26  17708766593513600591  corel corporation dvd movie factory 6 plus ret...   \n",
       "2    9949258255997064102                         money prem 2007 cd minibox   \n",
       "59   4377533611520192512           hijack2 identity and data security suite   \n",
       "48  18391195855196917401  symantec 11859201 be sys recovery 7.0 win sbs ...   \n",
       "40  13255609368261584070                        wingnuts 2: raina's revenge   \n",
       "37  16814254064816255791  prosoft engineering data rescue universal license   \n",
       "52  18422068306669698354  microsoft h22-00301 gov open sa project svr w9...   \n",
       "55  18446496383812786183                                   cookn vegetarian   \n",
       "87  13804410937823415271  aquarium 3-in-one limited edition (win 95 98 m...   \n",
       "77   9167720084838534914  sony media software cinescore soundtrack creat...   \n",
       "50  18384557845547191313                          east west bosendorfer 290   \n",
       "73  18365507478568694929                  microsoft 059-03871 molpc word sa   \n",
       "\n",
       "                                          description    manufacturer  \\\n",
       "66  combustion 4.0 professional compositing softwa...             NaN   \n",
       "0   adobe cs3 production premium mac upgrade from ...  adobe software   \n",
       "81  encore software 33027 : hoyle texas hold em le...             NaN   \n",
       "26  uleadÂ® dvd moviefactoryÂ® 6 plus is easy-to-u...             NaN   \n",
       "2   money premium 2007 win32 english north america...       microsoft   \n",
       "59  prevent thieves from accessing any of your per...             NaN   \n",
       "48        be sys recovery 7.0 win sbs ed media cd m/l             NaN   \n",
       "40  system requirements: mac os x 10.4+ g4/g5/inte...             NaN   \n",
       "37  do you have a corrupt hard drive or one that n...             NaN   \n",
       "52                     gov open sa project svr w9x nt             NaN   \n",
       "55  the diet choice for many world cultures for mi...             NaN   \n",
       "87  an amazing collection so vibrant and realistic...             NaN   \n",
       "77  cinescore - professional soundtrack creation s...             NaN   \n",
       "50  the pristine bosendorfer 290 piano library has...             NaN   \n",
       "73                                      molpc word sa             NaN   \n",
       "\n",
       "      price   Company  \n",
       "66      889  company2  \n",
       "0    805.99  company2  \n",
       "81     8.44  company2  \n",
       "26    74.08  company2  \n",
       "2     63.99  company2  \n",
       "59     44.9  company2  \n",
       "48    31.98  company2  \n",
       "40    28.99  company2  \n",
       "37   236.34  company2  \n",
       "52  1995.12  company2  \n",
       "55    19.99  company2  \n",
       "87    19.95  company2  \n",
       "77   179.95  company2  \n",
       "50   175.97  company2  \n",
       "73   111.78  company2  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2[company2['id'].isin(false_negatives['idCompany2'])].sort_values('price',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>9755705822363275907</td>\n",
       "      <td>autodesk combustion 4.0 compositing software -...</td>\n",
       "      <td>combustion 4.0 professional compositing softwa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>889</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               name  \\\n",
       "66  9755705822363275907  autodesk combustion 4.0 compositing software -...   \n",
       "\n",
       "                                          description manufacturer price  \\\n",
       "66  combustion 4.0 professional compositing softwa...          NaN   889   \n",
       "\n",
       "     Company  \n",
       "66  company2  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2[company2['id']==false_positives.iloc[f,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,5), max_df=0.10) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "#denselist = dense.tolist()\n",
    "#df = pd.DataFrame(denselist, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3073)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_names\n",
    "dense.shape #.head() 4589 rows × 12391 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 102\n",
      "Number of true positives: 88\n",
      "Number of false positives: 14\n",
      "Number of false negatives: 17\n",
      "Precision: 0.8627450980392157\n",
      "Recall: 0.8380952380952381\n",
      "F measure: 0.8502415458937198\n"
     ]
    }
   ],
   "source": [
    "##tfidf\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    try :  \n",
    "        price1 = float(company1.iloc[i,4]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    for j in range(len(company2)):\n",
    "        try :  \n",
    "            price2 = float(company2.iloc[j,4]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        if price1* price2 == 0:\n",
    "            price_ratio=1\n",
    "        else:\n",
    "            price_ratio =max(price1, price2)/min(price1, price2)\n",
    "        similarity = np.dot(dense[i],np.transpose(dense[len(company1)+j])).item(0)\n",
    "        if ((similarity > 0.15) and (price_ratio<3)):# or name_score<=1) :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.10) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "#denselist = dense.tolist()\n",
    "#df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(ngram_range=(3,5), max_df=0.10) #ngram_range=(1),\n",
    "vectors2 = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names2 = vectorizer.get_feature_names()\n",
    "dense2 = vectors.todense()\n",
    "#denselist = dense.tolist()\n",
    "#df = pd.DataFrame(denselist, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 106\n",
      "Number of true positives: 91\n",
      "Number of false positives: 15\n",
      "Number of false negatives: 14\n",
      "Precision: 0.8584905660377359\n",
      "Recall: 0.8666666666666667\n",
      "F measure: 0.8625592417061612\n"
     ]
    }
   ],
   "source": [
    "##tfidf\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    try :  \n",
    "        price1 = float(company1.iloc[i,4]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    for j in range(len(company2)):\n",
    "        try :  \n",
    "            price2 = float(company2.iloc[j,4]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        if price1* price2 == 0:\n",
    "            price_ratio=1\n",
    "        else:\n",
    "            price_ratio =max(price1, price2)/min(price1, price2)\n",
    "        similarity = np.dot(dense[i],np.transpose(dense[len(company1)+j])).item(0)\n",
    "        similarity2 = np.dot(dense2[i],np.transpose(dense2[len(company1)+j])).item(0)\n",
    "        if ((max(similarity,similarity2) > 0.25) and (price_ratio<2)):# or name_score<=1) :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>b000o27t8a</td>\n",
       "      <td>adobe creative suite cs3 design premium upgrad...</td>\n",
       "      <td>upgrade only; previous version of cs premium s...</td>\n",
       "      <td>adobe</td>\n",
       "      <td>599.0</td>\n",
       "      <td>company1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               name  \\\n",
       "30  b000o27t8a  adobe creative suite cs3 design premium upgrad...   \n",
       "\n",
       "                                          description manufacturer  price  \\\n",
       "30  upgrade only; previous version of cs premium s...        adobe  599.0   \n",
       "\n",
       "     Company  \n",
       "30  company1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=2\n",
    "company1[company1['id']==false_positives.iloc[f,0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>14054232840925252286</td>\n",
       "      <td>adobe cs3 design standard upgrade</td>\n",
       "      <td>system requirements powerpc g4 or g5 or intel ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413.99</td>\n",
       "      <td>company2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                               name  \\\n",
       "39  14054232840925252286  adobe cs3 design standard upgrade   \n",
       "\n",
       "                                          description manufacturer   price  \\\n",
       "39  system requirements powerpc g4 or g5 or intel ...          NaN  413.99   \n",
       "\n",
       "     Company  \n",
       "39  company2  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "company2[company2['id']==false_positives.iloc[f,1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "company1['clean_title']=company1['title'].apply(prep)\n",
    "company1['clean_descr']=company1['description'].apply(prep)\n",
    "company2['clean_name']=company2['name'].apply(prep)\n",
    "company2['clean_descr']=company2['description'].apply(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b00004tkvy</td>\n",
       "      <td>noah's ark activity center (jewel case ages 3-8)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>victory multimedia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>noah ark activ center jewel case age 3 8</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             title description  \\\n",
       "2  b00004tkvy  noah's ark activity center (jewel case ages 3-8)         NaN   \n",
       "\n",
       "         manufacturer  price                               clean_title  \\\n",
       "2  victory multimedia    0.0  noah ark activ center jewel case age 3 8   \n",
       "\n",
       "  clean_descr  \n",
       "2         nan  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1[company1.id == ground_truth_matches.idCompany1[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 5980\n",
      "Number of true positives: 1045\n",
      "Number of false positives: 4935\n",
      "Number of false negatives: 255\n",
      "Precision: 0.17474916387959866\n",
      "Recall: 0.8038461538461539\n",
      "F measure: 0.2870879120879121\n"
     ]
    }
   ],
   "source": [
    "##Methode Christophe\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    tokens1name = nltk.word_tokenize(company1.iloc[i,5])\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    #print(ng1_tokensname)\n",
    "    for j in range(len(company2)):\n",
    "        tokens2name = nltk.word_tokenize(company2.iloc[j,5])\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        name_score = nltk.edit_distance(company1.iloc[i,5], company2.iloc[j,5])\n",
    "        )if ((jd_ng1_ng2_name <= 0.7)):# or name_score<=1) :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 97\n",
      "Number of true positives: 79\n",
      "Number of false positives: 18\n",
      "Number of false negatives: 27\n",
      "Precision: 0.8144329896907216\n",
      "Recall: 0.7452830188679245\n",
      "F measure: 0.7783251231527093\n"
     ]
    }
   ],
   "source": [
    "##Methode 2 : jaccard distance en mixant nom et manufacturer\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    tokens1name = nltk.word_tokenize(company1.iloc[i,5] + ' ' + str(company1.iloc[i,3]))\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    #print(ng1_tokensname)\n",
    "    for j in range(len(company2)):\n",
    "        tokens2name = nltk.word_tokenize(company2.iloc[j,5] + ' ' + str(company2.iloc[j,3]))\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        name_score = nltk.edit_distance(company1.iloc[i,5] , company2.iloc[j,5] )\n",
    "        if (jd_ng1_ng2_name <= 0.75) : #or name_score<=1 :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,3))\n",
    "transformed_descrip1 = tfidf.fit_transform(company1['clean_descr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_descrip1_as_array = transformed_descrip1.toarray()\n",
    "len(transformed_descrip1_as_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '000 clipart', '000 clipart digit', '000 hand', '000 hand select', '000 headlin', '000 headlin images2', '000 imag', '000 imag mean', '000 industri', '000 industri profil', '000 opentyp', '000 opentyp font', '000 per', '000 per sag', '000 photo', '000 photo easi', '000 royalti', '000 royalti free', '000 select']\n"
     ]
    }
   ],
   "source": [
    "feature_names1=tfidf.get_feature_names()\n",
    "print(feature_names1[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 38\n",
      "Number of true positives: 38\n",
      "Number of false positives: 0\n",
      "Number of false negatives: 64\n",
      "Precision: 1.0\n",
      "Recall: 0.37254901960784315\n",
      "F measure: 0.5428571428571428\n"
     ]
    }
   ],
   "source": [
    "##Methode 3 : idem avec des n-grams de 2\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    tokens1name = nltk.word_tokenize(company1.iloc[i,1] + ' ' + str(company1.iloc[i,3]))\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=2))\n",
    "    #print(ng1_tokensname)\n",
    "    for j in range(len(company2)):\n",
    "        tokens2name = nltk.word_tokenize(company2.iloc[j,1] + ' ' + str(company2.iloc[j,3]))\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=2))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        name_score = nltk.edit_distance(company1.iloc[i,1] , company2.iloc[j,1] )\n",
    "        if (jd_ng1_ng2_name <= 0.7) : #or name_score<=1 :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 25\n",
      "Number of true positives: 25\n",
      "Number of false positives: 0\n",
      "Number of false negatives: 75\n",
      "Precision: 1.0\n",
      "Recall: 0.25\n",
      "F measure: 0.4\n"
     ]
    }
   ],
   "source": [
    "##Methode 4 : idem avec des n-grams de 3\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    tokens1name = nltk.word_tokenize(company1.iloc[i,1] + ' ' + str(company1.iloc[i,3]))\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=3))\n",
    "    #print(ng1_tokensname)\n",
    "    for j in range(len(company2)):\n",
    "        tokens2name = nltk.word_tokenize(company2.iloc[j,1] + ' ' + str(company2.iloc[j,3]))\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=3))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        name_score = nltk.edit_distance(company1.iloc[i,1] , company2.iloc[j,1] )\n",
    "        if (jd_ng1_ng2_name <= 0.75) : #or name_score<=1 :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 38\n",
      "Number of true positives: 32\n",
      "Number of false positives: 6\n",
      "Number of false negatives: 70\n",
      "Precision: 0.8421052631578947\n",
      "Recall: 0.3137254901960784\n",
      "F measure: 0.45714285714285713\n"
     ]
    }
   ],
   "source": [
    "##Methode 4 : jaccard distance en mixant nom, description et manufacturer\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    tokens1name = nltk.word_tokenize(company1.iloc[i,1] + ' ' + str(company1.iloc[i,2]) + ' ' + str(company1.iloc[i,3]))\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    #print(ng1_tokensname)\n",
    "    for j in range(len(company2)):\n",
    "        tokens2name = nltk.word_tokenize(company2.iloc[j,1] + ' ' + str(company2.iloc[j,2]) + ' ' + str(company2.iloc[j,3]))\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        name_score = nltk.edit_distance(company1.iloc[i,1] , company2.iloc[j,1] )\n",
    "        if (jd_ng1_ng2_name <= 0.8) : #or name_score<=1 :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 91\n",
      "Number of true positives: 81\n",
      "Number of false positives: 10\n",
      "Number of false negatives: 24\n",
      "Precision: 0.8901098901098901\n",
      "Recall: 0.7714285714285715\n",
      "F measure: 0.8265306122448981\n"
     ]
    }
   ],
   "source": [
    "##Methode 5 : methode 2 + price ratio<3\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "for i in range(len(company1)):\n",
    "    try :  \n",
    "        price1 = float(company1.iloc[i,4]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    tokens1name = nltk.word_tokenize(str(company1.iloc[i,3]) + ' ' + company1.iloc[i,1])\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    #print(ng1_tokensname)\n",
    "    for j in range(len(company2)):\n",
    "        try :  \n",
    "            price2 = float(company2.iloc[j,4]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        if price1* price2 == 0:\n",
    "            price_ratio=1\n",
    "        else:\n",
    "            price_ratio =max(price1, price2)/min(price1, price2)\n",
    "        tokens2name = nltk.word_tokenize(str(company2.iloc[j,3]) + ' ' + company2.iloc[j,1]  )\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        name_score = nltk.edit_distance(company1.iloc[i,1] , company2.iloc[j,1] )\n",
    "        if ((jd_ng1_ng2_name <= 0.65) and price_ratio<3) or ((jd_ng1_ng2_name <= 0.75) and price_ratio<1.25): #or name_score<=1 :\n",
    "            number_of_matches = number_of_matches +1\n",
    "            matches.append((company1.iloc[i,0],company2.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the two records share the same value for attributes 'name' and 'address'. However, they have slightly different values for the columns 'city' and 'cuisine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>18374143831267894200</td>\n",
       "      <td>sound studio 3 for mac</td>\n",
       "      <td>easytouse mac os x application for recording a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                    name  \\\n",
       "78  18374143831267894200  sound studio 3 for mac   \n",
       "\n",
       "                                          description manufacturer  price  \n",
       "78  easytouse mac os x application for recording a...          NaN  79.99  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nan',\n",
       " 'weekly',\n",
       " 'reader',\n",
       " 'preparing',\n",
       " 'for',\n",
       " 'kindergarten',\n",
       " '2008',\n",
       " '(',\n",
       " 'pc/mac',\n",
       " ')',\n",
       " 'fogware']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, on the other hand, the two records are associated with different names, cities and cuisiones.\n",
    "\n",
    "This file represents a simple example of datasets, on which we can experiment with th etechniques presented in the course to try identify duplicates, without using (that is relying on the values of) the column \"unique_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by adding a new column to identify the records (lines) in our dataframe\n",
    "df_restaurants.insert(0,'record_ID', range(0, len(df_restaurants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exhaustive comparisons: every record is compared with every other record\n",
    "\n",
    "We start by applying an exhaustive strategy whereby every record in the CSV file, is compared with every other record. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below does this for us. In doing so, it uses the following rule:\n",
    "\n",
    "For two records to match, i.e. refer to the same restaurant in the real world:\n",
    "* The edit distance between the attribute name values of the two records needs to be smaller or equal to 3, and \n",
    "* they need to have the same value for the cuisine attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants[df_restaurants.record_ID.isin([43, 622])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records = len(df_restaurants)\n",
    "matches = []\n",
    "matchescomplet = []\n",
    "\n",
    "number_of_matches = 0\n",
    "tokens1=[]\n",
    "tokens2=[]\n",
    "start = time.process_time()\n",
    "for i in range(0,num_records):\n",
    "    \n",
    "    # Après tokenization , calcul du ngrams (n=1) pour le name qui servira pour la Jaccard distance, pour la ligne i\n",
    "    tokens1name = nltk.word_tokenize(df_restaurants.iloc[i,1]) \n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    \n",
    "    # Après tokenization , calcul du ngrams (n=1) pour l'adresse qui servira pour la Jaccard distance,, pour la ligne i\n",
    "    tokens1adr = nltk.word_tokenize(df_restaurants.iloc[i,2]) \n",
    "    ng1_tokensadr = set(nltk.ngrams(tokens1adr, n=1))\n",
    "    \n",
    "    \n",
    "    for j in range(i+1,num_records):\n",
    "        \n",
    "        # Après tokenization , calcul du ngrams (n=1) pour le name qui servira pour la Jaccard distance, , pour la ligne j\n",
    "        tokens2name = nltk.word_tokenize( df_restaurants.iloc[j,1]) \n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        \n",
    "        # Après tokenization , calcul du ngrams (n=1) pour le name qui servira pour la Jaccard distance, , pour la ligne j\n",
    "        tokens2adr = nltk.word_tokenize( df_restaurants.iloc[j,2]) \n",
    "        ng2_tokensadr = set(nltk.ngrams(tokens2adr, n=1))\n",
    "       \n",
    "        # calcul de la Jaccard distance pour le name entre la ligne i et la ligne j (\"item based\" avec ngrams (n=1)) \n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)  # jaccard distance entre les ngram=1 des names\n",
    "        \n",
    "        # calcul de la Jaccard distance pour l'adresse entre la ligne i et la ligne j (\"item based\" avec ngrams (n=1)) \n",
    "        jd_ng1_ng2_adr = nltk.jaccard_distance(ng1_tokensadr, ng2_tokensadr)  # jaccard distance entre les ngram=1 des adresses\n",
    "    \n",
    "        # Rule for matching: \n",
    "        # disjonction entre une similarité entre les names (name_score<=1) \n",
    "        # et une similarité conjugée entre les adresses et les noms (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6)\n",
    "        name_score = nltk.edit_distance(df_restaurants.iloc[i,1], df_restaurants.iloc[j,1])\n",
    "        \n",
    "        # Rule for matching: Distance between names is smaller or equal to 3 and the cuisine is the same \n",
    "        if (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6) or name_score<=1 :\n",
    "            number_of_matches = number_of_matches +1 \n",
    "            # matchescomplet.append((df_restaurants.iloc[i,0],df_restaurants.iloc[i,1], df_restaurants.iloc[i,2],df_restaurants.iloc[i,5], df_restaurants.iloc[j,0],df_restaurants.iloc[j,1], df_restaurants.iloc[j,2],df_restaurants.iloc[j,5]))\n",
    "            matches.append((df_restaurants.iloc[i,0],df_restaurants.iloc[j,0]))\n",
    "\n",
    "end = time.process_time()\n",
    "\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "for _ in matchescomplet:\n",
    "     print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quelques tests pour ajuster les critères de notre algorithme\n",
    "name_score = nltk.edit_distance(df_restaurants.iloc[73,1], df_restaurants.iloc[763,1])\n",
    "name_score   # 11\n",
    "# comme on le voit ci-dessous, la différence est le mot \"restaurant\", l'edit distance est très importante (11), \n",
    "# on ne peut pas se baser dessus pour dire que c le même resto, il faut qu'on ajoute un critère \"item based\" \n",
    "# en plus du critère edit_distance name_score<=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qq tests pour ajuster les critères de notre alogorithme\n",
    "df_restaurants[df_restaurants.record_ID.isin([73, 763])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_score = nltk.edit_distance(df_restaurants.iloc[32,1], df_restaurants.iloc[759,1])\n",
    "#print(name_score)\n",
    "tokens1 = nltk.word_tokenize(df_restaurants.iloc[73,1]) \n",
    "tokens2 = nltk.word_tokenize( df_restaurants.iloc[763,1]) \n",
    "print(tokens1)\n",
    "print(tokens2)\n",
    "ng1_tokens = set(nltk.ngrams(tokens1, n=1))\n",
    "ng2_tokens = set(nltk.ngrams(tokens2, n=1))\n",
    "print(ng1_tokens)\n",
    "print(ng2_tokens)\n",
    "\n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_tokens, ng2_tokens)\n",
    "print(jd_sent_1_2)\n",
    "# jd_ng1_ng2_adr <= 0.6,ce seuil de 0.6 suffira dire que les lignes 32 et 759 sont le même restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adresse\n",
    "#print(name_score)\n",
    "tokens1 = nltk.word_tokenize(df_restaurants.iloc[73,2]) \n",
    "tokens2 = nltk.word_tokenize( df_restaurants.iloc[763,2]) \n",
    "print(tokens1)\n",
    "print(tokens2)\n",
    "ng1_tokens = set(nltk.ngrams(tokens1, n=1))\n",
    "ng2_tokens = set(nltk.ngrams(tokens2, n=1))\n",
    "print(ng1_tokens)\n",
    "print(ng2_tokens)\n",
    "\n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_tokens, ng2_tokens)\n",
    "print(jd_sent_1_2)\n",
    "# ça ne passe pas , mais c pas grave car mettre le seuil à 0.67 va nous rajouter beaucoup de faux positifs \n",
    "# on a testé ce seuil plus élevé de 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_score = nltk.edit_distance(df_restaurants.iloc[6,1], df_restaurants.iloc[754,1])\n",
    "name_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_score = nltk.edit_distance(df_restaurants.iloc[32,1], df_restaurants.iloc[759,1])\n",
    "#print(name_score)\n",
    "tokens1 = nltk.word_tokenize(df_restaurants.iloc[6,1]) \n",
    "tokens2 = nltk.word_tokenize( df_restaurants.iloc[754,1]) \n",
    "print(tokens1)\n",
    "print(tokens2)\n",
    "ng1_tokens = set(nltk.ngrams(tokens1, n=1))\n",
    "ng2_tokens = set(nltk.ngrams(tokens2, n=1))\n",
    "print(ng1_tokens)\n",
    "print(ng2_tokens)\n",
    "\n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_tokens, ng2_tokens)\n",
    "print(jd_sent_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_score = nltk.edit_distance(df_restaurants.iloc[6,1], df_restaurants.iloc[754,1])\n",
    "name_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_score = nltk.edit_distance(df_restaurants.iloc[32,1], df_restaurants.iloc[759,1])\n",
    "#print(name_score)\n",
    "tokens1 = nltk.word_tokenize(df_restaurants.iloc[32,1]) \n",
    "tokens2 = nltk.word_tokenize( df_restaurants.iloc[759,1]) \n",
    "print(tokens1)\n",
    "print(tokens2)\n",
    "ng1_tokens = set(nltk.ngrams(tokens1, n=1))\n",
    "ng2_tokens = set(nltk.ngrams(tokens2, n=1))\n",
    "print(ng1_tokens)\n",
    "print(ng2_tokens)\n",
    "\n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_tokens, ng2_tokens)\n",
    "print(jd_sent_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "for match in matches:\n",
    "    print(\"The following records {} and {} match\".format(match[0],match[1]))\n",
    "    print(\"The restaurants with the following names {} and {} match.\".format(df_restaurants.iloc[match[0],1],df_restaurants.iloc[match[1],1]))\n",
    "    print(\"The restaurants with the following addresses {} and {} match.\".format(df_restaurants.iloc[match[0],2],df_restaurants.iloc[match[1],2]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the rule applied in the above code is not great. You may want to try other kind of distances, other thresholds, and other rules to identify matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the quality of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we first need to compute the ground truth (that is the list of correct matches) considering the attribute unique_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches = pd.read_csv(\"./restaurants.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches.insert(0, 'record_ID', range(0, len(ground_truth_matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches = pd.merge(ground_truth_matches,\n",
    "                                ground_truth_matches,\n",
    "                                on = 'unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_truth_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches = ground_truth_matches.query('record_ID_x < record_ID_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches = ground_truth_matches[['record_ID_x','record_ID_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truth_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ground_truth_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['record_ID_x','record_ID_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on s'assure que les couples record_ID_x et record_ID_y sont dans le bons sens (record_ID_x < record_ID_y)\n",
    "# comme dans ground_truth\n",
    "matches_df[matches_df['record_ID_x'] >= matches_df['record_ID_y'] ]\n",
    "# 0 lignes trouvées , donc c OK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idCompany1</th>\n",
       "      <th>idCompany2</th>\n",
       "      <th>Exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b0002ibev4</td>\n",
       "      <td>1887899244694755891</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b0007lw22g</td>\n",
       "      <td>18398718226932431716</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>b0001wn16m</td>\n",
       "      <td>10092468528845066077</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>b000ozhfsq</td>\n",
       "      <td>18438075297130458214</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>b00006sijr</td>\n",
       "      <td>6247936198343071793</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idCompany1            idCompany2 Exist\n",
       "0  b0002ibev4   1887899244694755891  both\n",
       "1  b0007lw22g  18398718226932431716  both\n",
       "5  b0001wn16m  10092468528845066077  both\n",
       "7  b000ozhfsq  18438075297130458214  both\n",
       "9  b00006sijr   6247936198343071793  both"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# les vrais duplicats que notre algo a pu détecter\n",
    "true_positives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of a true positive\n",
    "df_restaurants[df_restaurants.record_ID.isin(['6','754'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idCompany1</th>\n",
       "      <th>idCompany2</th>\n",
       "      <th>Exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>b0000c6fjm</td>\n",
       "      <td>18394964067436310447</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>b0000c6fjm</td>\n",
       "      <td>10092468528845066077</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>b000ndibq4</td>\n",
       "      <td>9761533219806554318</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>b000o27t8a</td>\n",
       "      <td>9761533219806554318</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>b000o27t8a</td>\n",
       "      <td>14054232840925252286</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idCompany1            idCompany2       Exist\n",
       "103  b0000c6fjm  18394964067436310447  right_only\n",
       "104  b0000c6fjm  10092468528845066077  right_only\n",
       "105  b000ndibq4   9761533219806554318  right_only\n",
       "106  b000o27t8a   9761533219806554318  right_only\n",
       "107  b000o27t8a  14054232840925252286  right_only"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notre algo les a sortis comme restos en double mais c pas vrai\n",
    "false_positives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notre critère de duplicate :\n",
    "# (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6) or (name_score<=1 and jd_ng1_ng2_adr <= 0.6) \n",
    "# eliminer grace jd_ng1_ng2_adr = 0.6666\n",
    "df_restaurants[df_restaurants.record_ID.isin(['55','56'])]\n",
    "# le name est le même donc l'algo dit que ce le même restaurant alors que ce n'est pas vrai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pareil c pas le même resto alors que l'algo les a retenu comme duplicate\n",
    "# car les names diffèrent d'un seul caractère.\n",
    "df_restaurants[df_restaurants.record_ID.isin(['87','88'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_score<=1\n",
    "name_score = nltk.edit_distance(df_restaurants.iloc[87,1], df_restaurants.iloc[88,1])\n",
    "name_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idCompany1</th>\n",
       "      <th>idCompany2</th>\n",
       "      <th>Exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b000ofnri8</td>\n",
       "      <td>12244614697089679523</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b0007d8r5k</td>\n",
       "      <td>13775362651326388438</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b00099qrok</td>\n",
       "      <td>9755705822363275907</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>b0002e3g6o</td>\n",
       "      <td>18384557845547191313</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>b0009yx9be</td>\n",
       "      <td>1021042895134770712</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idCompany1            idCompany2      Exist\n",
       "2  b000ofnri8  12244614697089679523  left_only\n",
       "3  b0007d8r5k  13775362651326388438  left_only\n",
       "4  b00099qrok   9755705822363275907  left_only\n",
       "6  b0002e3g6o  18384557845547191313  left_only\n",
       "8  b0009yx9be   1021042895134770712  left_only"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# les vrais duplicates que l'algo n'a pas détecté\n",
    "false_negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants[df_restaurants.record_ID.isin(['32','759'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faux négatif\n",
    "# pour l'algo le 32 et le 759 c'est pas le même restaurant, pourtant c le même\n",
    "# en effet les names diffèrents en lettres et en mots : \n",
    "# name_score > 1 et jd_ng1_ng2_name > 0.6 (ça suffit pour l'algo pour l'éliminer ) et en plus jd_ng1_ng2_adr > 0.6\n",
    "name_score = nltk.edit_distance(df_restaurants.iloc[32,1], df_restaurants.iloc[759,1])\n",
    "name_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # (jd_ng1_ng2_adr <= 0.6) and jd_ng1_ng2_name <= 0.6) or (name_score<=1)\n",
    "    \n",
    "# name_score = nltk.edit_distance(df_restaurants.iloc[32,1], df_restaurants.iloc[759,1])\n",
    "\n",
    "tokens1 = nltk.word_tokenize(df_restaurants.iloc[32,1])   # name\n",
    "tokens2 = nltk.word_tokenize( df_restaurants.iloc[759,1]) \n",
    "print(tokens1)\n",
    "print(tokens2)\n",
    "ng1_tokens = set(nltk.ngrams(tokens1, n=1))\n",
    "ng2_tokens = set(nltk.ngrams(tokens2, n=1))\n",
    "print(ng1_tokens)\n",
    "print(ng2_tokens)\n",
    "\n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_tokens, ng2_tokens)\n",
    "print(jd_sent_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # (jd_ng1_ng2_adr <= 0.6) and (name_score<=2 or jd_ng1_ng2_name <= 0.67)\n",
    "    \n",
    "# name_score = nltk.edit_distance(df_restaurants.iloc[32,1], df_restaurants.iloc[759,1])\n",
    "#print(name_score)\n",
    "tokens1 = nltk.word_tokenize(df_restaurants.iloc[73,2])   # adresse \n",
    "tokens2 = nltk.word_tokenize( df_restaurants.iloc[763,2]) \n",
    "print(tokens1)\n",
    "print(tokens2)\n",
    "ng1_tokens = set(nltk.ngrams(tokens1, n=1))\n",
    "ng2_tokens = set(nltk.ngrams(tokens2, n=1))\n",
    "print(ng1_tokens)\n",
    "print(ng2_tokens)\n",
    "\n",
    "jd_sent_1_2 = nltk.jaccard_distance(ng1_tokens, ng2_tokens)\n",
    "print(jd_sent_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ground_truth_matches))\n",
    "print(len(matches_df))\n",
    "print(len(true_positives) , 'true_positives')\n",
    "print(len(false_positives) ,'false_positives')\n",
    "print(len(false_negatives)  , 'false_negatives')\n",
    "\n",
    "# len(true_positives)  +  len(false_negatives) = len(ground_truth_matches)\n",
    "\n",
    "# len(matches_df)) - len(false_positif) + len(false_negatives)     = ground_truth_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you are using pyton 2.7 (instead of Python 3), you would need to convert integers to float prior to performing the division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(f_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windowing (SNM) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 841 842\n",
    "# qq tests pour choisir sur quel champ on va faire le sort \n",
    "# le sorted name parait intéressant\n",
    "df_restaurants.sort_values(by=['name']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le tri est fait dans ce qui suit selon le champ \"name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50   # \n",
    "\n",
    "# tri par name car c ce qui permet d'avoir des resto en double les plus proches possibles \n",
    "\n",
    "df_restaurants= df_restaurants.sort_values(by=['name'])  \n",
    "\n",
    "number_of_matchesw = 0\n",
    "num_records = len(df_restaurants)\n",
    "matchesw = []\n",
    "matchescompletw = []\n",
    "\n",
    "start = time.process_time()\n",
    "for i in range(0,min(window,len(df_restaurants))):\n",
    "    \n",
    "    tokens1name = nltk.word_tokenize(df_restaurants.iloc[i,1]) \n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    \n",
    "    tokens1adr = nltk.word_tokenize(df_restaurants.iloc[i,2]) \n",
    "    ng1_tokensadr = set(nltk.ngrams(tokens1adr, n=1))\n",
    "    \n",
    "    \n",
    "    for j in range(i+1,min(window,len(df_restaurants))):\n",
    "        tokens2name = nltk.word_tokenize( df_restaurants.iloc[j,1]) \n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        \n",
    "        \n",
    "        tokens2adr = nltk.word_tokenize( df_restaurants.iloc[j,2]) \n",
    "        ng2_tokensadr = set(nltk.ngrams(tokens2adr, n=1))\n",
    "#         print(tokens1)\n",
    "#         print(tokens2)       \n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)  # jaccard distance entre les ngram=1 des names\n",
    "        jd_ng1_ng2_adr = nltk.jaccard_distance(ng1_tokensadr, ng2_tokensadr)  # jaccard distance entre les ngram=1 des adresses\n",
    "    \n",
    "        name_score = nltk.edit_distance(df_restaurants.iloc[i,1], df_restaurants.iloc[j,1])\n",
    "        \n",
    "        # Rule for matching: Distance between names is smaller or equal to 3 and the cuisine is the same \n",
    "        if (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6) or name_score<=1 :\n",
    "            number_of_matchesw = number_of_matchesw +1 \n",
    "            # matchescomplet.append((df_restaurants.iloc[i,0],df_restaurants.iloc[i,1], df_restaurants.iloc[i,2],df_restaurants.iloc[i,5], df_restaurants.iloc[j,0],df_restaurants.iloc[j,1], df_restaurants.iloc[j,2],df_restaurants.iloc[j,5]))\n",
    "            matchesw.append((df_restaurants.iloc[i,0],df_restaurants.iloc[j,0]))\n",
    "            matchescompletw.append((df_restaurants.iloc[i,0],df_restaurants.iloc[i,1], df_restaurants.iloc[i,2],df_restaurants.iloc[i,5], df_restaurants.iloc[j,0],df_restaurants.iloc[j,1], df_restaurants.iloc[j,2],df_restaurants.iloc[j,5]))\n",
    "                     \n",
    "            \n",
    "            \n",
    "for i in range(window,len(df_restaurants)):\n",
    "    \n",
    "    tokens1name = nltk.word_tokenize(df_restaurants.iloc[i,1]) \n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    \n",
    "    tokens1adr = nltk.word_tokenize(df_restaurants.iloc[i,2]) \n",
    "    ng1_tokensadr = set(nltk.ngrams(tokens1adr, n=1))\n",
    "    \n",
    "    \n",
    "    for j in range(i-window+1,i):\n",
    "        tokens2name = nltk.word_tokenize( df_restaurants.iloc[j,1]) \n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        \n",
    "        \n",
    "        tokens2adr = nltk.word_tokenize( df_restaurants.iloc[j,2]) \n",
    "        ng2_tokensadr = set(nltk.ngrams(tokens2adr, n=1))\n",
    "     \n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)  # jaccard distance entre les ngram=1 des names\n",
    "        jd_ng1_ng2_adr = nltk.jaccard_distance(ng1_tokensadr, ng2_tokensadr)  # jaccard distance entre les ngram=1 des adresses\n",
    "    \n",
    "        name_score = nltk.edit_distance(df_restaurants.iloc[i,1], df_restaurants.iloc[j,1])\n",
    "        \n",
    "        # Rule for matching: Distance between names is smaller or equal to 3 and the cuisine is the same \n",
    "        if (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6) or name_score<=1 :\n",
    "            number_of_matchesw = number_of_matchesw +1 \n",
    "            # matchescomplet.append((df_restaurants.iloc[i,0],df_restaurants.iloc[i,1], df_restaurants.iloc[i,2],df_restaurants.iloc[i,5], df_restaurants.iloc[j,0],df_restaurants.iloc[j,1], df_restaurants.iloc[j,2],df_restaurants.iloc[j,5]))\n",
    "            matchesw.append((df_restaurants.iloc[i,0],df_restaurants.iloc[j,0]))\n",
    "            matchescompletw.append((df_restaurants.iloc[i,0],df_restaurants.iloc[i,1], df_restaurants.iloc[i,2],df_restaurants.iloc[i,5], df_restaurants.iloc[j,0],df_restaurants.iloc[j,1], df_restaurants.iloc[j,2],df_restaurants.iloc[j,5]))\n",
    "            \n",
    "end = time.process_time()\n",
    "\n",
    "print(\"Number of matches: {}\".format(number_of_matchesw))\n",
    "print(\"Processing time: {}\".format(end - start))            \n",
    "for _ in matchescompletw:\n",
    "     print(_)  \n",
    "# for _ in matches:\n",
    "#      print(_)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "for match in matchesw:\n",
    "    print(\"The following records {} and {} match\".format(match[0],match[1]))\n",
    "    print(\"The restaurants with the following names {} and {} match.\".format(df_restaurants.iloc[match[0],1],df_restaurants.iloc[match[1],1]))\n",
    "    print(\"The restaurants with the following addresses {} and {} match.\".format(df_restaurants.iloc[match[0],2],df_restaurants.iloc[match[1],2]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matchesw_df = pd.DataFrame(matchesw)\n",
    "matchesw_df.columns= ['record_ID_x','record_ID_y']\n",
    "\n",
    "matchesw_df['MIN'] = matchesw_df[['record_ID_x','record_ID_y']].min(axis=1)\n",
    "matchesw_df['MAX'] = matchesw_df[['record_ID_x','record_ID_y']].max(axis=1)\n",
    "matchesw_df=matchesw_df[['MIN','MAX']]\n",
    "matchesw_df.columns=['record_ID_x','record_ID_y']\n",
    "matchesw_df\n",
    "\n",
    "\n",
    "diffw_df = pd.merge(ground_truth_matches, matchesw_df, how='outer', indicator='Exist')\n",
    "true_positivesw = diffw_df[diffw_df.Exist=='both']\n",
    "false_positivesw = diffw_df[diffw_df.Exist=='right_only']\n",
    "false_negativesw = diffw_df[diffw_df.Exist=='left_only']\n",
    "precisionw = len(true_positivesw)/(len(true_positivesw)+ len(false_positivesw))\n",
    "print(precisionw)\n",
    "recallw = len(true_positivesw)/(len(true_positivesw)+ len(false_negativesw))\n",
    "print(recallw)\n",
    "f_measurew = 2*(precisionw*recallw)/(precisionw+recallw)\n",
    "print(f_measurew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ground_truth_matches))\n",
    "print(len(matchesw_df))\n",
    "print(len(true_positivesw))\n",
    "print(len(false_positivesw))\n",
    "print(len(false_negativesw))  \n",
    "# len(true_positives)  +  len(false_negatives) = len(ground_truth_matches)\n",
    "# len(matches_df)) - len(false_positif) + len(false_negatives)     = ground_truth_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that in the above code, we do not implement the SNM algorithm in its entirety. In particular, we do not implement the last phase of inferring matches using transitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants = pd.read_csv(\"./restaurants.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by adding a new column to identify the records (lines) in our dataframe\n",
    "df_restaurants.insert(0,'record_ID', range(0, len(df_restaurants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The blocks correspond to resturants that are located in the same citydf_restaurants.loc[df_restaurants['city']==' atlanta']\n",
    "df_restaurants.loc[df_restaurants['city']==' atlanta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants.loc[df_restaurants['city'].str.strip()=='atlanta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va créer un dict \"df_restov\" des restaurants de chaque ville\n",
    "# pour une clé= ville, la valeur du dict serait égale à un dataframe représentant les restos de cette ville\n",
    "df_restov= {}\n",
    "for ville in df_restaurants['city'].unique():\n",
    "    \n",
    "    df_restov[ville]   = df_restaurants.loc[df_restaurants['city']==ville]\n",
    "    num_records = len(df_restov[ville])\n",
    "    print(ville)   # on affiche la ville\n",
    "    print(num_records) # on affiche le nombre de restos par ville\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on vérifie  pour atlanta que ça marche bien, on a bien le dataframe qu'on voudrait.\n",
    "print(type(df_restov[\" atlanta\"]))\n",
    "print(df_restov[\" atlanta\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restov[\" atlanta\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on testel'algo précédent sur juste un dataframe celui des restos de \" atlanta\"  (avec un espace devant)\n",
    "num_records = len(df_restov[\" atlanta\"])\n",
    "amatches = []\n",
    "amatchescomplet = []\n",
    "\n",
    "anumber_of_matches = 0\n",
    "tokens1=[]\n",
    "tokens2=[]\n",
    "start = time.process_time()\n",
    "for i in range(0,num_records):\n",
    "    \n",
    "    # Après tokenization , calcul du ngrams (n=1) pour le name qui servira pour la Jaccard distance, pour la ligne i\n",
    "    tokens1name = nltk.word_tokenize(df_restov[\" atlanta\"].iloc[i,1]) \n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    \n",
    "    # Après tokenization , calcul du ngrams (n=1) pour l'adresse qui servira pour la Jaccard distance,, pour la ligne i\n",
    "    tokens1adr = nltk.word_tokenize(df_restov[\" atlanta\"].iloc[i,2]) \n",
    "    ng1_tokensadr = set(nltk.ngrams(tokens1adr, n=1))\n",
    "    \n",
    "    \n",
    "    for j in range(i+1,num_records):\n",
    "        \n",
    "        # Après tokenization , calcul du ngrams (n=1) pour le name qui servira pour la Jaccard distance, , pour la ligne j\n",
    "        tokens2name = nltk.word_tokenize( df_restov[\" atlanta\"].iloc[j,1]) \n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        \n",
    "        # Après tokenization , calcul du ngrams (n=1) pour le name qui servira pour la Jaccard distance, , pour la ligne j\n",
    "        tokens2adr = nltk.word_tokenize( df_restov[\" atlanta\"].iloc[j,2]) \n",
    "        ng2_tokensadr = set(nltk.ngrams(tokens2adr, n=1))\n",
    "     \n",
    "        # calcul de la Jaccard distance pour le name entre la ligne i et la ligne j (\"item based\" avec ngrams (n=1)) \n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        \n",
    "        # calcul de la Jaccard distance pour l'adresse entre la ligne i et la ligne j (\"item based\" avec ngrams (n=1)) \n",
    "        jd_ng1_ng2_adr = nltk.jaccard_distance(ng1_tokensadr, ng2_tokensadr)  \n",
    "    \n",
    "        name_score = nltk.edit_distance(df_restov[\" atlanta\"].iloc[i,1], df_restov[\" atlanta\"].iloc[j,1])\n",
    "        \n",
    "        # Rule for matching: \n",
    "        # disjonction entre une similarité entre les names (name_score<=1) \n",
    "        # et une similarité conjugée entre les adresses et les noms (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6)\n",
    "        if (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6) or name_score<=1 :\n",
    "            anumber_of_matches = anumber_of_matches +1 \n",
    "            matchescomplet.append((df_restov[\" atlanta\"].iloc[i,0],df_restov[\" atlanta\"].iloc[i,1], \\\n",
    "            df_restov[\" atlanta\"].iloc[i,2],df_restov[\" atlanta\"].iloc[i,3], df_restov[\" atlanta\"].iloc[i,5], \\\n",
    "            df_restov[\" atlanta\"].iloc[j,0],df_restov[\" atlanta\"].iloc[j,1], df_restov[\" atlanta\"].iloc[j,2], \\\n",
    "            df_restov[\" atlanta\"].iloc[j,3],df_restov[\" atlanta\"].iloc[j,5]))\n",
    "            amatches.append((df_restov[\" atlanta\"].iloc[i,0],df_restov[\" atlanta\"].iloc[j,0]))\n",
    "\n",
    "end = time.process_time()\n",
    "\n",
    "print(\"Number of matches: {}\".format(anumber_of_matches))\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "for _ in amatchescomplet:\n",
    "     print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nous allons refaire le dict mais en éliminant les espaces saisis avant et après chaque ville\n",
    "# par précaution pour éviter des villes en double\n",
    "# et nous allons imprimer le nombre de restos par ville.\n",
    "\n",
    "df_restov={}\n",
    "cumul= 0\n",
    "# il faut enlever les espaces au début et à la fin de chaque ville dans le dataframe, \n",
    "# sinon on va rater des restos en double car ils ne seront pas dans le même block.\n",
    "\n",
    "for ville in df_restaurants['city'].str.strip().unique():   \n",
    "     print(ville)\n",
    "     df_restov[ville]   = df_restaurants.loc[df_restaurants['city'].str.strip()==ville]\n",
    "     print(len(df_restov[ville]))\n",
    "     cumul += len(df_restov[ville])\n",
    "\n",
    "print(cumul)\n",
    "# on vérifie qu'on retrouve bien un total de 865 restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Généralisation de la BLOCKING METHOD à toutes les villes \n",
    "bmatches = []\n",
    "bmatchescomplet = []\n",
    "bnumber_of_matches = 0\n",
    "start = time.process_time()\n",
    "    \n",
    "for ville in df_restaurants['city'].str.strip().unique():\n",
    "        # affichage de la ville et du nombre de restos par ville\n",
    "        # pour les matcher entre eux\n",
    "        print(ville)  \n",
    "        num_records = len(df_restov[ville])\n",
    "        print(num_records)\n",
    "        \n",
    "        tokens1=[]\n",
    "        tokens2=[]\n",
    "       \n",
    "        for i in range(0,num_records):\n",
    "\n",
    "            tokens1name = nltk.word_tokenize(df_restov[ville].iloc[i,1]) \n",
    "            ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "\n",
    "            tokens1adr = nltk.word_tokenize(df_restov[ville].iloc[i,2]) \n",
    "            ng1_tokensadr = set(nltk.ngrams(tokens1adr, n=1))\n",
    "\n",
    "\n",
    "            for j in range(i+1,num_records):\n",
    "\n",
    "                tokens2name = nltk.word_tokenize( df_restov[ville].iloc[j,1]) \n",
    "                ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "\n",
    "\n",
    "                tokens2adr = nltk.word_tokenize( df_restov[ville].iloc[j,2]) \n",
    "                ng2_tokensadr = set(nltk.ngrams(tokens2adr, n=1))\n",
    "\n",
    "                jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)  # jaccard distance entre les ngram=1 des names\n",
    "                jd_ng1_ng2_adr = nltk.jaccard_distance(ng1_tokensadr, ng2_tokensadr)  # jaccard distance entre les ngram=1 des adresses\n",
    "\n",
    "                name_score = nltk.edit_distance(df_restov[ville].iloc[i,1], df_restov[ville].iloc[j,1])\n",
    "\n",
    "                # Rule for matching: Item based Jaccard Distance with ngram=1 between adresses and between names or edit distance between names \n",
    "                if (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6) or name_score<=1 :\n",
    "                    bnumber_of_matches = bnumber_of_matches +1 \n",
    "                    bmatchescomplet.append((df_restov[ville].iloc[i,0],df_restov[ville].iloc[i,1], \\\n",
    "                    df_restov[ville].iloc[i,2],df_restov[ville].iloc[i,3], df_restov[ville].iloc[i,5], \\\n",
    "                    df_restov[ville].iloc[j,0],df_restov[ville].iloc[j,1], df_restov[ville].iloc[j,2], \\\n",
    "                    df_restov[ville].iloc[j,3],df_restov[ville].iloc[j,5]))\n",
    "                    bmatches.append((df_restov[ville].iloc[i,0],df_restov[ville].iloc[j,0]))\n",
    "\n",
    "end = time.process_time()\n",
    "\n",
    "print(\"Number of matches: {}\".format(bnumber_of_matches))\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "# for _ in matchescomplet:\n",
    "#        print(_)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rappel des résultats de l'algo original sans blocking:\n",
    "####  Number of matches: 127\n",
    "#### Processing time: 167.984375\n",
    "\n",
    "#### les infos de l'algo avec  blocking ci-dessus\n",
    "#### Number of matches: 67\n",
    "#### Processing time: 25.6875\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ground_truth_matches = pd.read_csv(\"./restaurants.csv\")\n",
    "len(ground_truth_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches.insert(0, 'record_ID', range(0, len(ground_truth_matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches = pd.merge(ground_truth_matches,\n",
    "                                ground_truth_matches,\n",
    "                                on = 'unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches = ground_truth_matches.query('record_ID_x < record_ID_y')\n",
    "len(ground_truth_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matches = ground_truth_matches[['record_ID_x','record_ID_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmatches_df = pd.DataFrame(bmatches)\n",
    "bmatches_df.columns= ['record_ID_x','record_ID_y']\n",
    "bmatches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on s'assure que les couples record_ID_x et record_ID_y sont dans le bons sens (record_ID_x < record_ID_y)\n",
    "bmatches_df[bmatches_df['record_ID_x'] >= bmatches_df['record_ID_y'] ]\n",
    "# 0 lignes trouvées , donc c OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = pd.merge(ground_truth_matches, bmatches_df, how='outer', indicator='Exist')\n",
    "diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrue_positives = diff_df[diff_df.Exist=='both']\n",
    "bfalse_positives = diff_df[diff_df.Exist=='right_only']\n",
    "bfalse_negatives = diff_df[diff_df.Exist=='left_only']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un vrai positif: c un vrai couple de restos en double qui a été détecté par notre algo sous forme de blocking method.\n",
    "# en effet il vérifie le critère de name (edit_distance=0) et en plus les 2 restos se trouve dans la même ville d'atlanta.\n",
    "df_restaurants[df_restaurants.record_ID.isin(['6','754'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les couples détectés par notre algo comme des doubles mais à tort, ce ne sont pas des doubles.\n",
    "false_positives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants[df_restaurants.record_ID.isin(['96','196'])]\n",
    "# ce couple n'est pas dans le ground_truth car unique_id différent\n",
    "# mais il est dans le bmatches_df , (jd_ng1_ng2_adr <= 0.6 and jd_ng1_ng2_name <= 0.6) \n",
    "# cad les names sont proches pour la jaccard distance item based\n",
    "# et les adresses sont proches pour la jaccard distance item based.\n",
    "# et en plus ils se trouvent dans la même ville atlanta (blocking method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les couples de restos en double mais qui ne sont pas détectés par notre algo comme des doubles.\n",
    "false_negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants[df_restaurants.record_ID.isin(['2','753'])]\n",
    "# ce couple est dans le ground_truth car même unique_id \n",
    "# mais il n'est pas dans le matches_df, malgré qu' ils ont le même name et la  même adresse (dans l'algo les détecte bien)\n",
    "# mais le Blocking method ne permet pas à l'algo de les matcher car ils sont considérés ayant des villes différentes :\n",
    "# 'new york' et 'new york city'  , à cause d'une mauvaise saisie de la ville."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bfalse_negatives) # y a beaucoup de false_ngatives par rapport à l'algo dans Blocking method (on avait 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negative\n",
    "df_restaurants[df_restaurants.record_ID.isin(['26','756'])]\n",
    "# du au blocking method : new yor et new york city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negative\n",
    "df_restaurants[df_restaurants.record_ID.isin(['32','759'])]\n",
    "# dû aux matching imprécis de l'algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false negative\n",
    "df_restaurants[df_restaurants.record_ID.isin(['36','760'])]\n",
    "# du au blocking method : new yor et new york city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ground_truth_matches))\n",
    "print(len(bmatches_df))\n",
    "print(len(btrue_positives) , 'true_positives')\n",
    "print(len(bfalse_positives) ,'false_positives')\n",
    "print(len(bfalse_negatives)  , 'false_negatives')\n",
    "\n",
    "# len(true_positives)  +  len(false_negatives) = len(ground_truth_matches)\n",
    "\n",
    "# len(matches_df)) - len(false_positif) + len(false_negatives)     = ground_truth_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bprecision = len(btrue_positives)/(len(btrue_positives)+ len(bfalse_positives))\n",
    "print(bprecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brecall = len(btrue_positives)/(len(btrue_positives)+ len(bfalse_negatives))\n",
    "print(brecall)\n",
    "# recall faible car y a beaucoup de false negatives\n",
    "# y a des duplicates que l'algo avec Blocking method n'a pas détecté car saisie à tort dans des villes différentes\n",
    "# surtout new york et new york city "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_measure = 2*(bprecision*brecall)/(bprecision+brecall)\n",
    "print(bf_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chiffres de l'algo original sans blocking method\n",
    "### precision: 0.7795\n",
    "\n",
    "### recall : 0.8839\n",
    "\n",
    "### f_measure :0.82845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
