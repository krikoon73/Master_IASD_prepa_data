{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini projet Qualité de Données : Détections des doublons\n",
    "## ***Christophe COMPAIN / Sander COHEN***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif et Données Disponibles\n",
    "L'objectif du projet est d'identifier les logiciels vendus sur les deux plateformes.\n",
    "\n",
    "Pour ce faire, nous disposons des données pour chacune des plateformes isolément, respectivement dans les fichiers ***Company1.csv*** et ***Company2.csv***. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages, Variables Globales et import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\scohe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\scohe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\OneDrive - Université Paris-Dauphine\\\\Bureau\\\\Cours Master\\\\12-Qualité de Données\\\\\\Projet\\\\mini-projet\\\\\"\n",
    "file1= \"Data\\\\Company1.csv\" #\"SampleData\\\\Sample_Company1.csv\"\n",
    "file2= \"Data\\\\Company2.csv\" #\"SampleData\\\\Sample_Company2.csv\"\n",
    "real= \"Data\\\\Ground_truth_mappings.csv\" #\"SampleData\\\\Sample_Groud_truth_mappings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "company1 = pd.read_csv(path+file1, encoding = \"ISO-8859-1\")\n",
    "company2 = pd.read_csv(path+file2, encoding = \"ISO-8859-1\")\n",
    "ground_truth_matches = pd.read_csv(path+real, encoding = \"ISO-8859-1\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b000jz4hqo</td>\n",
       "      <td>clickart 950 000 - premier image pack (dvd-rom)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>broderbund</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b0006zf55o</td>\n",
       "      <td>ca international - arcserve lap/desktop oem 30pk</td>\n",
       "      <td>oem arcserve backup v11.1 win 30u for laptops ...</td>\n",
       "      <td>computer associates</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b00004tkvy</td>\n",
       "      <td>noah's ark activity center (jewel case ages 3-8)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>victory multimedia</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b000g80lqo</td>\n",
       "      <td>peachtree by sage premium accounting for nonpr...</td>\n",
       "      <td>peachtree premium accounting for nonprofits 20...</td>\n",
       "      <td>sage software</td>\n",
       "      <td>599.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b0006se5bq</td>\n",
       "      <td>singing coach unlimited</td>\n",
       "      <td>singing coach unlimited - electronic learning ...</td>\n",
       "      <td>carry-a-tune technologies</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0  b000jz4hqo    clickart 950 000 - premier image pack (dvd-rom)   \n",
       "1  b0006zf55o   ca international - arcserve lap/desktop oem 30pk   \n",
       "2  b00004tkvy   noah's ark activity center (jewel case ages 3-8)   \n",
       "3  b000g80lqo  peachtree by sage premium accounting for nonpr...   \n",
       "4  b0006se5bq                            singing coach unlimited   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1  oem arcserve backup v11.1 win 30u for laptops ...   \n",
       "2                                                NaN   \n",
       "3  peachtree premium accounting for nonprofits 20...   \n",
       "4  singing coach unlimited - electronic learning ...   \n",
       "\n",
       "                manufacturer   price  \n",
       "0                 broderbund    0.00  \n",
       "1        computer associates    0.00  \n",
       "2         victory multimedia    0.00  \n",
       "3              sage software  599.99  \n",
       "4  carry-a-tune technologies   99.99  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11125907881740407428</td>\n",
       "      <td>learning quickbooks 2007</td>\n",
       "      <td>learning quickbooks 2007</td>\n",
       "      <td>intuit</td>\n",
       "      <td>38.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11538923464407758599</td>\n",
       "      <td>superstart! fun with reading &amp; writing!</td>\n",
       "      <td>fun with reading &amp; writing! is designed to hel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11343515411965421256</td>\n",
       "      <td>qb pos 6.0 basic software</td>\n",
       "      <td>qb pos 6.0 basic retail mngmt software. for re...</td>\n",
       "      <td>intuit</td>\n",
       "      <td>637.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12049235575237146821</td>\n",
       "      <td>math missions: the amazing arcade adventure (g...</td>\n",
       "      <td>save spectacle city by disrupting randall unde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12244614697089679523</td>\n",
       "      <td>production prem cs3 mac upgrad</td>\n",
       "      <td>adobe cs3 production premium mac upgrade from ...</td>\n",
       "      <td>adobe software</td>\n",
       "      <td>805.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               name  \\\n",
       "0  11125907881740407428                           learning quickbooks 2007   \n",
       "1  11538923464407758599            superstart! fun with reading & writing!   \n",
       "2  11343515411965421256                          qb pos 6.0 basic software   \n",
       "3  12049235575237146821  math missions: the amazing arcade adventure (g...   \n",
       "4  12244614697089679523                     production prem cs3 mac upgrad   \n",
       "\n",
       "                                         description    manufacturer   price  \n",
       "0                           learning quickbooks 2007          intuit   38.99  \n",
       "1  fun with reading & writing! is designed to hel...             NaN    8.49  \n",
       "2  qb pos 6.0 basic retail mngmt software. for re...          intuit  637.99  \n",
       "3  save spectacle city by disrupting randall unde...             NaN   12.95  \n",
       "4  adobe cs3 production premium mac upgrade from ...  adobe software  805.99  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idCompany1</th>\n",
       "      <th>idCompany2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b000jz4hqo</td>\n",
       "      <td>18441480711193821750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b00004tkvy</td>\n",
       "      <td>18441110047404795849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b000g80lqo</td>\n",
       "      <td>18441188461196475272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b0006se5bq</td>\n",
       "      <td>18428750969726461849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b00021xhzw</td>\n",
       "      <td>18430621475529168165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idCompany1            idCompany2\n",
       "0  b000jz4hqo  18441480711193821750\n",
       "1  b00004tkvy  18441110047404795849\n",
       "2  b000g80lqo  18441188461196475272\n",
       "3  b0006se5bq  18428750969726461849\n",
       "4  b00021xhzw  18430621475529168165"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_matches.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation d'un premier duplicat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b00004tkvy</td>\n",
       "      <td>noah's ark activity center (jewel case ages 3-8)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>victory multimedia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             title description  \\\n",
       "2  b00004tkvy  noah's ark activity center (jewel case ages 3-8)         NaN   \n",
       "\n",
       "         manufacturer  price  \n",
       "2  victory multimedia    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company1[company1.id == ground_truth_matches.idCompany1[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1881</td>\n",
       "      <td>18441110047404795849</td>\n",
       "      <td>the beginners bible: noah's ark activity cente...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               name  \\\n",
       "1881  18441110047404795849  the beginners bible: noah's ark activity cente...   \n",
       "\n",
       "     description manufacturer price  \n",
       "1881         NaN          NaN  9.95  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2[company2.id == ground_truth_matches.idCompany2[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))  \n",
    "stop_words.update([\"r\",\"v\",\"software\",\"entertainment\",\"inc\",\"usa\"])\n",
    "\n",
    "def prep(texte):\n",
    "    #suppression des caracteres non alphanumériques + tout en minuscule\n",
    "    texte = re.sub(\"[^a-zA-Z0-9_]\", \" \",str(texte)).lower()\n",
    "    #remplacement de mots\n",
    "    texte = texte.replace(\"professional\", \"pro\").replace(\" upg \",\" upgrade \").replace(\" dlx \",\" deluxe \")\n",
    "    #tokenization par mot\n",
    "    tokens = nltk.word_tokenize(texte)\n",
    "    #supreesion des stopwords\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words]\n",
    "#    # Stemming\n",
    "#    texte = [nltk.stem.SnowballStemmer('english').stem(w) for w in filtered_tokens]\n",
    "    # Lemmatization\n",
    "    texte = [nltk.stem.WordNetLemmatizer().lemmatize(w) for w in filtered_tokens]\n",
    "    #remise sous forme d'une string\n",
    "    return \" \".join(texte)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##retraitement des prix\n",
    "def retreatprice(texte):\n",
    "    #suppression des caracteres non alphanumériques + tout en minuscule\n",
    "    return float(re.sub(\"[^0-9.]\", \" \",str(texte)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "company1['Company']=\"company1\"\n",
    "company1=company1.rename(columns={\"title\": \"name\"})\n",
    "company1['name'] = company1['name'].fillna(' ')\n",
    "company1['manufacturer'] = company1['manufacturer'].fillna(' ')\n",
    "company1['description'] = company1['description'].fillna(' ')\n",
    "company1['price'] = company1['price'].fillna(' ')\n",
    "company1['price_retreat'] = company1['price'].apply(retreatprice)\n",
    "company1['full data']=company1['manufacturer'].apply(prep) + ' ' + company1['name'].apply(prep) # + ' ' + company1['description'].apply(prep)\n",
    "\n",
    "company2['Company']=\"company2\"\n",
    "company2['name'] = company2['name'].fillna(' ')\n",
    "company2['manufacturer'] = company2['manufacturer'].fillna(' ')\n",
    "company2['description'] = company2['description'].fillna(' ')\n",
    "company2['price'] = company2['price'].fillna(' ')\n",
    "company2['price_retreat'] = company2['price'].apply(retreatprice)\n",
    "company2['full data']=company2['manufacturer'].apply(prep) + ' ' + company2['name'].apply(prep) # + ' ' + company2['description'].apply(prep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "      <th>Company</th>\n",
       "      <th>price_retreat</th>\n",
       "      <th>full data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4584</td>\n",
       "      <td>14872602878188858026</td>\n",
       "      <td>jumpstart(r) advanced 1st grade</td>\n",
       "      <td>prepare your child for the 1st grade and beyon...</td>\n",
       "      <td></td>\n",
       "      <td>19.99</td>\n",
       "      <td>company2</td>\n",
       "      <td>19.99</td>\n",
       "      <td>jumpstart advanced 1st grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4585</td>\n",
       "      <td>14916162814320983138</td>\n",
       "      <td>ibm(r) viavoice(r) advanced edition 10</td>\n",
       "      <td>ibm viavoice advanced edition release 10 is a ...</td>\n",
       "      <td></td>\n",
       "      <td>78.95</td>\n",
       "      <td>company2</td>\n",
       "      <td>78.95</td>\n",
       "      <td>ibm viavoice advanced edition 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4586</td>\n",
       "      <td>14974113209571399013</td>\n",
       "      <td>xbox 360: gears of war</td>\n",
       "      <td>as marcus fenix you fight a war against the im...</td>\n",
       "      <td></td>\n",
       "      <td>59.99</td>\n",
       "      <td>company2</td>\n",
       "      <td>59.99</td>\n",
       "      <td>xbox 360 gear war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4587</td>\n",
       "      <td>14986935400648190776</td>\n",
       "      <td>documents to go premium 7.0</td>\n",
       "      <td>this pda software enables you to use your docu...</td>\n",
       "      <td></td>\n",
       "      <td>49.99</td>\n",
       "      <td>company2</td>\n",
       "      <td>49.99</td>\n",
       "      <td>document go premium 7 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4588</td>\n",
       "      <td>14996991014087320062</td>\n",
       "      <td>microsoft(r) picture it! digital image pro 9.0</td>\n",
       "      <td>picture it! digital image pro puts you in cont...</td>\n",
       "      <td></td>\n",
       "      <td>99.87</td>\n",
       "      <td>company2</td>\n",
       "      <td>99.87</td>\n",
       "      <td>microsoft picture digital image pro 9 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                            name  \\\n",
       "4584  14872602878188858026                 jumpstart(r) advanced 1st grade   \n",
       "4585  14916162814320983138          ibm(r) viavoice(r) advanced edition 10   \n",
       "4586  14974113209571399013                          xbox 360: gears of war   \n",
       "4587  14986935400648190776                     documents to go premium 7.0   \n",
       "4588  14996991014087320062  microsoft(r) picture it! digital image pro 9.0   \n",
       "\n",
       "                                            description manufacturer  price  \\\n",
       "4584  prepare your child for the 1st grade and beyon...               19.99   \n",
       "4585  ibm viavoice advanced edition release 10 is a ...               78.95   \n",
       "4586  as marcus fenix you fight a war against the im...               59.99   \n",
       "4587  this pda software enables you to use your docu...               49.99   \n",
       "4588  picture it! digital image pro puts you in cont...               99.87   \n",
       "\n",
       "       Company  price_retreat                                 full data  \n",
       "4584  company2          19.99              jumpstart advanced 1st grade  \n",
       "4585  company2          78.95          ibm viavoice advanced edition 10  \n",
       "4586  company2          59.99                         xbox 360 gear war  \n",
       "4587  company2          49.99                   document go premium 7 0  \n",
       "4588  company2          99.87   microsoft picture digital image pro 9 0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.concat([company1, company2],sort=False,ignore_index=True)\n",
    "#corpus.reset_index(drop=True)\n",
    "len(corpus)\n",
    "corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recherche des mots unique pour les supprimer\n",
    "allwords = corpus['full data'].str.split(expand=True).stack().value_counts()\n",
    "stop_unique = set(allwords[allwords==1].index)\n",
    "\n",
    "def prep2(texte):\n",
    "    tokens = nltk.word_tokenize(texte)\n",
    "    #supreesion des stopwords\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words]\n",
    "    #remise sous forme d'une string\n",
    "    return \" \".join(filtered_tokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "company1['full data']=company1['full data'].apply(prep)\n",
    "company2['full data']=company2['full data'].apply(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#company1_light = company1[company1['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "#company2_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 57\n",
      "Processing time: 0.25\n",
      "Number of true positives: 28\n",
      "Number of false positives: 29\n",
      "Number of false negatives: 1272\n",
      "Precision: 0.49122807017543857\n",
      "Recall: 0.021538461538461538\n",
      "F measure: 0.041267501842299194\n"
     ]
    }
   ],
   "source": [
    "###données punch software\n",
    "filtre = \"punch\"\n",
    "#stopwords_suppl =\" software\"\n",
    "company1_light = company1[company1['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "company2_light = company2[company2['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.5,sublinear_tf=True,stop_words=[filtre])#+stopwords_suppl]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "number_of_matches = 0\n",
    "matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "    try :  \n",
    "        price1 = float(company1_light.iloc[i,6]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "        try :  \n",
    "            price2 = float(company2_light.iloc[j,6]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if  ((similarity > 0.35)) :#or jd_ng1_ng2_name<0.1 :# or name_score<=1) :\n",
    "                number_of_matches = number_of_matches +1\n",
    "                matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "print(\"Number of matches: {}\".format(number_of_matches))\n",
    "matches_df = pd.DataFrame(matches)\n",
    "matches_df.columns= ['idCompany1','idCompany2']\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 48\n",
      "Total matches: 105\n",
      "Processing time: 0.734375\n",
      "Number of true positives: 58\n",
      "Number of false positives: 47\n",
      "Number of false negatives: 1242\n",
      "Precision: 0.5523809523809524\n",
      "Recall: 0.04461538461538461\n",
      "F measure: 0.08256227758007116\n"
     ]
    }
   ],
   "source": [
    "###données topics\n",
    "filtre = \"topic\"\n",
    "#stopwords_suppl =\" entertainment\"\n",
    "company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "company1_light = company1_light[company1_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "company2_light = company2_light[company2_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.05,sublinear_tf=True,stop_words=[filtre]) #+stopwords_suppl]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "new_number_of_matches = 0\n",
    "new_matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "    try :  \n",
    "        price1 = float(company1_light.iloc[i,6]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "        try :  \n",
    "            price2 = float(company2_light.iloc[j,6]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if  ((similarity > 0.3)) or jd_ng1_ng2_name<0.2 :# or name_score<=1) :\n",
    "                new_number_of_matches = new_number_of_matches +1\n",
    "                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "print(\"New matches: {}\".format(new_number_of_matches))\n",
    "number_of_matches= number_of_matches + new_number_of_matches\n",
    "print(\"Total matches: {}\".format(number_of_matches))\n",
    "new_matches_df = pd.DataFrame(new_matches)\n",
    "new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 66\n",
      "Total matches: 171\n",
      "Processing time: 0.609375\n",
      "Number of true positives: 106\n",
      "Number of false positives: 65\n",
      "Number of false negatives: 1194\n",
      "Precision: 0.6198830409356725\n",
      "Recall: 0.08153846153846153\n",
      "F measure: 0.1441196464989803\n"
     ]
    }
   ],
   "source": [
    "###données apple\n",
    "filtre = \"apple\"\n",
    "company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "company1_light = company1_light[company1_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "company2_light = company2_light[company2_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.1,sublinear_tf=True,stop_words=[filtre]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "new_number_of_matches = 0\n",
    "new_matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "    try :  \n",
    "        price1 = float(company1_light.iloc[i,6]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "        try :  \n",
    "            price2 = float(company2_light.iloc[j,6]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if  ((similarity > 0.4)) or jd_ng1_ng2_name<0.5 :# or name_score<=1) :\n",
    "                new_number_of_matches = new_number_of_matches +1\n",
    "                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "print(\"New matches: {}\".format(new_number_of_matches))\n",
    "number_of_matches= number_of_matches + new_number_of_matches\n",
    "print(\"Total matches: {}\".format(number_of_matches))\n",
    "new_matches_df = pd.DataFrame(new_matches)\n",
    "new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 132\n",
      "Total matches: 303\n",
      "Processing time: 7.328125\n",
      "Number of true positives: 198\n",
      "Number of false positives: 105\n",
      "Number of false negatives: 1102\n",
      "Precision: 0.6534653465346535\n",
      "Recall: 0.1523076923076923\n",
      "F measure: 0.24703680598877104\n"
     ]
    }
   ],
   "source": [
    "###données Encore\n",
    "filtre = \"encore\"\n",
    "company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "company1_light = company1_light[company1_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "company2_light = company2_light[company2_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.01,sublinear_tf=True,stop_words=[filtre]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "new_number_of_matches = 0\n",
    "new_matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "    try :  \n",
    "        price1 = float(company1_light.iloc[i,6]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "        try :  \n",
    "            price2 = float(company2_light.iloc[j,6]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if ((similarity > 0.2)) or jd_ng1_ng2_name<0.2 :# or name_score<=1) :\n",
    "                new_number_of_matches = new_number_of_matches +1\n",
    "                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "print(\"New matches: {}\".format(new_number_of_matches))\n",
    "number_of_matches= number_of_matches + new_number_of_matches\n",
    "print(\"Total matches: {}\".format(number_of_matches))\n",
    "new_matches_df = pd.DataFrame(new_matches)\n",
    "new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 86\n",
      "Total matches: 389\n",
      "Processing time: 4.328125\n",
      "Number of true positives: 247\n",
      "Number of false positives: 142\n",
      "Number of false negatives: 1053\n",
      "Precision: 0.6349614395886889\n",
      "Recall: 0.19\n",
      "F measure: 0.29248075784487865\n"
     ]
    }
   ],
   "source": [
    "###données Adobe\n",
    "filtre = \"adobe\"\n",
    "company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "company1_light = company1_light[company1_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "company2_light = company2_light[company2_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.5,sublinear_tf=True,stop_words=[filtre]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "new_number_of_matches = 0\n",
    "new_matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "    try :  \n",
    "        price1 = float(company1_light.iloc[i,6]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "        try :  \n",
    "            price2 = float(company2_light.iloc[j,6]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if ((similarity > 0.6)) :# jd_ng1_ng2_name<0.3 :# or name_score<=1) :\n",
    "                new_number_of_matches = new_number_of_matches +1\n",
    "                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "print(\"New matches: {}\".format(new_number_of_matches))\n",
    "number_of_matches= number_of_matches + new_number_of_matches\n",
    "print(\"Total matches: {}\".format(number_of_matches))\n",
    "new_matches_df = pd.DataFrame(new_matches)\n",
    "new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "\n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 67\n",
      "Total matches: 456\n",
      "Processing time: 4.171875\n",
      "Number of true positives: 278\n",
      "Number of false positives: 178\n",
      "Number of false negatives: 1022\n",
      "Precision: 0.6096491228070176\n",
      "Recall: 0.21384615384615385\n",
      "F measure: 0.3166287015945331\n"
     ]
    }
   ],
   "source": [
    "###données microsoft\n",
    "filtre = \"microsoft\"\n",
    "#stopwords_suppl =\" software\"\n",
    "company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "company1_light = company1_light[company1_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "company2_light = company2_light[company2_light['full data'].str.contains(filtre)].reset_index(drop=True)\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.5,sublinear_tf=True,stop_words=[filtre]) #+stopwords_suppl]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "new_number_of_matches = 0\n",
    "new_matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "    try :  \n",
    "        price1 = float(company1_light.iloc[i,6]) \n",
    "    except : \n",
    "        price1 = 0\n",
    "    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "        try :  \n",
    "            price2 = float(company2_light.iloc[j,6]) \n",
    "        except : \n",
    "            price2 = 0\n",
    "        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if ((similarity > 0.45)):# or name_score<=1) :\n",
    "                new_number_of_matches = new_number_of_matches +1\n",
    "                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "\n",
    "print(\"New matches: {}\".format(new_number_of_matches))\n",
    "number_of_matches= number_of_matches + new_number_of_matches\n",
    "print(\"Total matches: {}\".format(number_of_matches))\n",
    "new_matches_df = pd.DataFrame(new_matches)\n",
    "new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "                \n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 587\n",
      "Total matches: 1043\n",
      "Processing time: 660.5\n",
      "Number of true positives: 674\n",
      "Number of false positives: 369\n",
      "Number of false negatives: 626\n",
      "Precision: 0.6462128475551294\n",
      "Recall: 0.5184615384615384\n",
      "F measure: 0.5753307725138711\n"
     ]
    }
   ],
   "source": [
    "company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_df=0.01,sublinear_tf=True)#,stop_words=[\"software\"]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "new_number_of_matches = 0\n",
    "new_matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "#    try :  \n",
    "    price1 = float(company1_light.iloc[i,6]) \n",
    "#    except : \n",
    "#        price1 = 0\n",
    "#    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "#    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "#        try :  \n",
    "        price2 = float(company2_light.iloc[j,6]) \n",
    "#        except : \n",
    "#            price2 = 0\n",
    "#        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "#        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "#        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if ((similarity > 0.5)):# or name_score<=1) :\n",
    "                new_number_of_matches = new_number_of_matches +1\n",
    "                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "\n",
    "\n",
    "\n",
    "print(\"New matches: {}\".format(new_number_of_matches))\n",
    "number_of_matches= number_of_matches + new_number_of_matches\n",
    "print(\"Total matches: {}\".format(number_of_matches))\n",
    "new_matches_df = pd.DataFrame(new_matches)\n",
    "new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "\n",
    "\n",
    "matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "#matches_df_temp = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "                \n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "#diff_df = pd.merge(ground_truth_matches, matches_df_temp, how='outer', indicator='Exist')\n",
    "\n",
    "\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 163\n",
      "Total matches: 1206\n",
      "Processing time: 294.703125\n",
      "Number of true positives: 786\n",
      "Number of false positives: 420\n",
      "Number of false negatives: 514\n",
      "Precision: 0.6517412935323383\n",
      "Recall: 0.6046153846153847\n",
      "F measure: 0.627294493216281\n"
     ]
    }
   ],
   "source": [
    "company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.01,sublinear_tf=True)#,stop_words=[\"software\"]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "new_number_of_matches = 0\n",
    "new_matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "#    try :  \n",
    "    price1 = float(company1_light.iloc[i,6]) \n",
    "#    except : \n",
    "#        price1 = 0\n",
    "#    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "#    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "#        try :  \n",
    "        price2 = float(company2_light.iloc[j,6]) \n",
    "#        except : \n",
    "#            price2 = 0\n",
    "#        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "#        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "#        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if ((similarity > 0.5)):# or name_score<=1) :\n",
    "                new_number_of_matches = new_number_of_matches +1\n",
    "                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "\n",
    "\n",
    "\n",
    "print(\"New matches: {}\".format(new_number_of_matches))\n",
    "number_of_matches= number_of_matches + new_number_of_matches\n",
    "print(\"Total matches: {}\".format(number_of_matches))\n",
    "new_matches_df = pd.DataFrame(new_matches)\n",
    "new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "\n",
    "\n",
    "matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "###matches_df_temp = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "                \n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "###diff_df = pd.merge(ground_truth_matches, matches_df_temp, how='outer', indicator='Exist')\n",
    "\n",
    "\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 297\n",
      "Total matches: 2313\n",
      "Processing time: 40.046875\n",
      "Number of true positives: 931\n",
      "Number of false positives: 572\n",
      "Number of false negatives: 369\n",
      "Precision: 0.6194278110445776\n",
      "Recall: 0.7161538461538461\n",
      "F measure: 0.6642882625758117\n"
     ]
    }
   ],
   "source": [
    "company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), max_df=0.01,sublinear_tf=True)#,stop_words=[\"software\"]) #ngram_range=(1),\n",
    "vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "\n",
    "new_number_of_matches = 0\n",
    "new_matches=[]\n",
    "start = time.process_time()\n",
    "for i in range(len(company1_light)):\n",
    "#    try :  \n",
    "    price1 = float(company1_light.iloc[i,6]) \n",
    "#    except : \n",
    "#        price1 = 0\n",
    "#    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "#    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "    for j in range(len(company2_light)):\n",
    "#        try :  \n",
    "        price2 = float(company2_light.iloc[j,6]) \n",
    "#        except : \n",
    "#            price2 = 0\n",
    "#        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "#        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "#        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "            try :\n",
    "                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "            except : \n",
    "                similarity = 0\n",
    "            if ((similarity > 0.5)):# or name_score<=1) :\n",
    "                new_number_of_matches = new_number_of_matches +1\n",
    "                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "\n",
    "\n",
    "\n",
    "print(\"New matches: {}\".format(new_number_of_matches))\n",
    "number_of_matches= number_of_matches + new_number_of_matches\n",
    "print(\"Total matches: {}\".format(number_of_matches))\n",
    "new_matches_df = pd.DataFrame(new_matches)\n",
    "new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "\n",
    "\n",
    "matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "###matches_df_temp = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "                \n",
    "diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "###diff_df = pd.merge(ground_truth_matches, matches_df_temp, how='outer', indicator='Exist')\n",
    "\n",
    "\n",
    "true_positives = diff_df[diff_df.Exist=='both']\n",
    "false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "end = time.process_time()\n",
    "print(\"Processing time: {}\".format(end - start))\n",
    "print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "f_measure = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#company1_light=company1[~company1.id.isin(matches_df.idCompany1)]\n",
    "#company2_light=company2[~company2.id.isin(matches_df.idCompany2)]\n",
    "#corpus = pd.concat([company1_light, company2_light],sort=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matches: 50\n",
      "Total matches: 3212\n",
      "Processing time: 19.34375\n",
      "Number of true positives: 947\n",
      "Number of false positives: 606\n",
      "Number of false negatives: 353\n",
      "Precision: 0.6097875080489376\n",
      "Recall: 0.7284615384615385\n",
      "F measure: 0.6638626007711181\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = TfidfVectorizer(ngram_range=(1,1), max_df=0.01,sublinear_tf=True)#,stop_words=[\"software\"]) #ngram_range=(1),\n",
    "#vectors = vectorizer.fit_transform(corpus['full data'])\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#dense = vectors.todense()\n",
    "\n",
    "#new_number_of_matches = 0\n",
    "#new_matches=[]\n",
    "#start = time.process_time()\n",
    "#for i in range(len(company1_light)):\n",
    "##    try :  \n",
    "#    price1 = float(company1_light.iloc[i,6]) \n",
    "##    except : \n",
    "##        price1 = 0\n",
    "##    tokens1name = nltk.word_tokenize(company1_light.iloc[i,7])\n",
    "##    ng1_tokensname = set(nltk.ngrams(tokens1name, n=1))\n",
    "#    for j in range(len(company2_light)):\n",
    "##        try :  \n",
    "#        price2 = float(company2_light.iloc[j,6]) \n",
    "##        except : \n",
    "##            price2 = 0\n",
    "##        tokens2name = nltk.word_tokenize(company2_light.iloc[j,7])\n",
    "##        ng2_tokensname = set(nltk.ngrams(tokens2name, n=1))\n",
    "##        jd_ng1_ng2_name = nltk.jaccard_distance(ng1_tokensname, ng2_tokensname)\n",
    "#        if price1* price2 == 0 or max(price1, price2)/min(price1, price2)<2:\n",
    "#            try :\n",
    "#                similarity = np.dot(dense[i],np.transpose(dense[len(company1_light)+j])).item(0)/math.sqrt(np.dot(dense[i],np.transpose(dense[i])).item(0) * np.dot(dense[len(company1_light)+j],np.transpose(dense[len(company1_light)+j])).item(0))\n",
    "#            except : \n",
    "#                similarity = 0\n",
    "#            if ((similarity > 0.45)):# or name_score<=1) :\n",
    "#                new_number_of_matches = new_number_of_matches +1\n",
    "#                new_matches.append((company1_light.iloc[i,0],company2_light.iloc[j,0]))\n",
    "\n",
    "\n",
    "\n",
    "#print(\"New matches: {}\".format(new_number_of_matches))\n",
    "#number_of_matches= number_of_matches + new_number_of_matches\n",
    "#print(\"Total matches: {}\".format(number_of_matches))\n",
    "#new_matches_df = pd.DataFrame(new_matches)\n",
    "#new_matches_df.columns= ['idCompany1','idCompany2']\n",
    "\n",
    "\n",
    "###matches_df = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "#matches_df_temp = pd.concat([matches_df, new_matches_df],sort=False,ignore_index=True)\n",
    "                \n",
    "###diff_df = pd.merge(ground_truth_matches, matches_df, how='outer', indicator='Exist')\n",
    "#diff_df = pd.merge(ground_truth_matches, matches_df_temp, how='outer', indicator='Exist')\n",
    "\n",
    "\n",
    "#true_positives = diff_df[diff_df.Exist=='both']\n",
    "#false_positives = diff_df[diff_df.Exist=='right_only']\n",
    "#false_negatives = diff_df[diff_df.Exist=='left_only']\n",
    "#end = time.process_time()\n",
    "#print(\"Processing time: {}\".format(end - start))\n",
    "#print(\"Number of true positives: {}\".format(len(true_positives)))\n",
    "#print(\"Number of false positives: {}\".format(len(false_positives)))\n",
    "#print(\"Number of false negatives: {}\".format(len(false_negatives)))\n",
    "#precision = len(true_positives)/(len(true_positives)+ len(false_positives))\n",
    "#print(\"Precision: {}\".format(precision))\n",
    "#recall = len(true_positives)/(len(true_positives)+ len(false_negatives))\n",
    "#print(\"Recall: {}\".format(recall))\n",
    "#f_measure = 2*(precision*recall)/(precision+recall)\n",
    "#print(\"F measure: {}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_false_negatives =false_negatives.merge(corpus.loc[corpus['Company'] == 'company1']\n",
    "                                            .drop(['Company','name','manufacturer'], inplace=False, axis=1)\n",
    "                                            .rename(columns = {'id': 'idCompany1','description': 'descr1',\n",
    "                                                               'price': 'price1','full data': 'full data1'}\n",
    "                                                    , inplace = False)\n",
    "                                            , how='inner', on='idCompany1').merge(corpus.loc[corpus['Company'] == 'company2']\n",
    "                                                                                  .drop(['Company','name','manufacturer'], inplace=False, axis=1)\n",
    "                                                                                  .rename(columns = {'id': 'idCompany2', \n",
    "                                                                                                     'description': 'descr2', \n",
    "                                                                                                     'price': 'price2', \n",
    "                                                                                                     'full data': 'full data2'}, inplace = False)\n",
    "                                                                                  , how='inner', on='idCompany2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_false_positives =false_positives.merge(corpus.loc[corpus['Company'] == 'company1']\n",
    "                                            .drop(['Company','name','manufacturer'], inplace=False, axis=1)\n",
    "                                            .rename(columns = {'id': 'idCompany1','description': 'descr1',\n",
    "                                                               'price': 'price1','full data': 'full data1'}\n",
    "                                                    , inplace = False)\n",
    "                                            , how='inner', on='idCompany1').merge(corpus.loc[corpus['Company'] == 'company2']\n",
    "                                                                                  .drop(['Company','name','manufacturer'], inplace=False, axis=1)\n",
    "                                                                                  .rename(columns = {'id': 'idCompany2', \n",
    "                                                                                                     'description': 'descr2', \n",
    "                                                                                                     'price': 'price2', \n",
    "                                                                                                     'full data': 'full data2'}, inplace = False)\n",
    "                                                                                  , how='inner', on='idCompany2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_false_positives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "base_false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
